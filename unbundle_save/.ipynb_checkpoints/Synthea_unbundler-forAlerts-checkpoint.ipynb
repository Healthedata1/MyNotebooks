{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to create and save and load 3 Synthea bundles:\n",
    "\n",
    "### 1) Admit to ER \n",
    "\n",
    "- Bundle contains Encounter and all referenced resources - no Condition\n",
    "- Encounter\n",
    "  - status = in-progress\n",
    "  - class = EMER\n",
    "  - should be matched to same encounter with a business identifier but unique id in the Bundle?  Name+\"Admit-datetime\"\n",
    "  - for simplicity use the same location and practitioner\n",
    "  - type is unknown  \n",
    "- PUT to server to preserve the ID's and references\n",
    "\n",
    "\n",
    "### 2) Transfer from ER to Inpatient\n",
    "\n",
    "- Bundle contains updated Encounters and Condition\n",
    "- Encounter\n",
    "  - status = in-progress\n",
    "  - class = IMP\n",
    "  - should be matched to same encounter with same business identifier and id in the Bundle? Name+\"Admit-datetime\"\n",
    "  - for simplicity use the same location and practitioner\n",
    "  - type is examplotomy\n",
    "  - hospitalization reason = transfer\n",
    "- Condition\n",
    "  - Add Condition for Examplotomy\n",
    "\n",
    "\n",
    "### 3) Discharge from Inpatient\n",
    "\n",
    "- Bundle contains updated Encounters\n",
    "- Encounter\n",
    "  - status = finished\n",
    "  - class = IMP\n",
    "  - should be matched to same encounter with same business identifier and id in the Bundle? Name+\"Admit-datetime\"\n",
    "  - for simplicity use the same location and practitioner\n",
    "  - discharge disposition\n",
    "  - type is examplotomy - point to same Condition as transfer\n",
    "\n",
    "\n",
    "### Load to FHIR Reference Server for further testing\n",
    "\n",
    "\n",
    "- python version 3.6+\n",
    "- get data from folder\n",
    "- unbundle\n",
    "- display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path, unlink\n",
    "from json import load, dumps, loads\n",
    "from requests import get, post, put, delete\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from fhirclient.r4models import bundle as B\n",
    "from fhirclient.r4models import provenance as P\n",
    "from fhirclient.r4models import narrative as N\n",
    "import fhirclient.r4models.coding as C\n",
    "import fhirclient.r4models.codeableconcept as CC\n",
    "import fhirclient.r4models.fhirdate as D\n",
    "import fhirclient.r4models.fhirreference as FR\n",
    "import fhirclient.r4models.meta as M\n",
    "from fhirclient.r4models.fhirabstractbase import FHIRValidationError\n",
    "from datetime import datetime, date\n",
    "from requests import get, post, put\n",
    "from uuid import uuid1\n",
    "from time import sleep\n",
    "from pprint import pprint\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fhir_test_server = 'http://test.fhir.org/r4'\n",
    "fhir_test_server = 'http://hapi.fhir.org/baseR4'\n",
    "\n",
    "headers = {\n",
    "    'Accept':'application/fhir+json',\n",
    "    'Content-Type':'application/fhir+json',\n",
    "    }\n",
    "\n",
    "types = dict (\n",
    "Patient = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient',\n",
    "AllergyIntolerance = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-allergyintolerance',\n",
    "CarePlan = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-careplan',\n",
    "CareTeam = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-careteam',\n",
    "Condition = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-condition',\n",
    "Device = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-implantable-device',\n",
    "DiagnosticReport = ['http://hl7.org/fhir/us/core/StructureDefinition/us-core-diagnosticreport-lab',\n",
    "                    'http://hl7.org/fhir/us/core/StructureDefinition/us-core-diagnosticreport-note'],\n",
    "DocumentReference = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-documentreference',\n",
    "Encounter = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-encounter',\n",
    "Goal = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-goal',\n",
    "Immunization = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-immunization',\n",
    "Location = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-location',\n",
    "Medication = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-medication',\n",
    "MedicationRequest = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-medicationrequest',\n",
    "Observation = ['http://hl7.org/fhir/us/core/StructureDefinition/us-core-observation-lab',\n",
    "               'http://hl7.org/fhir/StructureDefinition/vitalsigns',\n",
    "                'http://hl7.org/fhir/us/core/StructureDefinition/us-core-smokingstatus',\n",
    "               'http://hl7.org/fhir/us/core/StructureDefinition/pediatric-weight-for-height',\n",
    "               'http://hl7.org/fhir/us/core/StructureDefinition/pediatric-bmi-for-age',\n",
    "               'http://hl7.org/fhir/us/core/StructureDefinition/us-core-pulse-oximetry',],\n",
    "Organization = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-organization',\n",
    "Practitioner = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitioner',\n",
    "PractitionerRole = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitionerrole',\n",
    "Procedure = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-procedure',\n",
    "Provenance = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-provenance',\n",
    ")\n",
    "\n",
    "\n",
    "#in_path = '/Users/ehaas/Documents/FHIR/synthea/output/fhir/'\n",
    "#in_path = '/Users/ehaas/Documents/FHIR/synthea/output/us_core_r4/fhir/'\n",
    "in_path='test/'\n",
    "out_path='out/'\n",
    "#out_path = '/Users/ehaas/Documents/FHIR/ArgoR4Validator/source/examples/'  # append forward slash \n",
    "#f_name = 'Denisse335_Stracke611_e760e08d-a0ff-4cd7-83c0-36b27dae6ec3'\n",
    "#f_name='Alaina222_Gleichner915_0e83bdc3-52c5-4e7e-ba92-174e711ba95c'\n",
    "#f_name = 'Nadia817_Morissette863_190017e3-417c-46d4-8c0e-dcc9dbc67d25.json'\n",
    "f_name = \"notify-2.json\"\n",
    "#f_name =\"notify-100.json\"\n",
    "f_now = D.FHIRDate(f'{datetime.utcnow().isoformat()}Z')\n",
    "f_now.as_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(in_path,f_name): # get files\n",
    "    with open(f'{in_path}{f_name}',encoding='utf-8', errors='ignore') as f:\n",
    "        r = f.read()\n",
    "        return(loads(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Clear the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_path():\n",
    "    for filename in listdir(out_path):\n",
    "        file_path = path.join(out_path,filename)\n",
    "        try:\n",
    "            if path.isfile(file_path):\n",
    "               unlink(file_path)\n",
    "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write file to examples dir in IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(r_json,type,id): # write file  \n",
    "    with open(f'{out_path}{type}-{id}.json', 'w') as f:\n",
    "        #print(f'Writing to {out_path}{type}-{id}.json')\n",
    "        f.write(r_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Organization from the Bundle to create Provenance resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefetch_org(b):\n",
    "    #bundle = B.Bundle(b, strict=False)\n",
    "    #prov_org = (i for i in bundle.entry if i.resource.resource_type =='Organization')\n",
    "    orgs = (i for i in b['entry'] if i['resource']['resourceType'] =='Organization')\n",
    "    org_id  = next(orgs)['resource']['id']\n",
    "    return(org_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Resources ( Teardown )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_r(t,r_id):\n",
    "    params = dict(\n",
    "    _cascade='delete',\n",
    "    )\n",
    "    r = delete(f'{fhir_test_server}/{t}/{r_id}', params = params, headers = headers)\n",
    "    return(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Resource Using $validate on Reference Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(b):\n",
    "    # note that bundle b is a json  \n",
    "    r = post(f'{fhir_test_server}/Bundle/$validate', headers = headers, data = b)\n",
    "    return(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Transaction Bundle to reference Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_transaction(b):\n",
    "    # note that bundle b is a json\n",
    "    # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    " \n",
    "    params = dict(\n",
    "      # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    "        )\n",
    "    \n",
    "    r = post(fhir_test_server, params = params, headers = headers, data = b)\n",
    "    return(r)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Provenance\n",
    "\n",
    "- Inputs:\n",
    "  - what resource is it about\n",
    "  - Prefetched Organization to use for the author and transmitter ( for now just one will do)\n",
    "- most everything else is a fixed value.\n",
    "- validate using the argovalidator  (load to examples)\n",
    "- add to bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_type(system,code):\n",
    "    \n",
    "    prov_type = CC.CodeableConcept()\n",
    "    prov_type_coding = C.Coding()\n",
    "    prov_type_coding.system = system\n",
    "    prov_type_coding.code = code\n",
    "    prov_type.coding = [prov_type_coding]\n",
    "    #print(prov_type)\n",
    "    return(prov_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prov(org,target_type, target_id):\n",
    "    \n",
    "  \n",
    "    who_ref=FR.FHIRReference(dict(\n",
    "                reference=f'Organization/{org}'\n",
    "        ))\n",
    "                             \n",
    "    prov_target = FR.FHIRReference(dict(\n",
    "            reference=f'{target_type}/{target_id}'\n",
    "        ))\n",
    "    \n",
    "    f_now = D.FHIRDate(f'{datetime.utcnow().isoformat()}Z')\n",
    "    \n",
    "    prov = P.Provenance()\n",
    "    prov.id = str(uuid1())\n",
    "    prov.meta = M.Meta(dict(profile =[types['Provenance']]))\n",
    "    prov.target= [prov_target]\n",
    "    prov.recorded = f_now\n",
    "    prov.agent = []\n",
    "    \n",
    "    # this could be a function\n",
    "    prov_agent = P.ProvenanceAgent()\n",
    "    prov_agent.who = who_ref\n",
    "    prov_agent.type = get_agent_type(system='http://hl7.org/fhir/us/core/CodeSystem/us-core-provenance-participant-type',code='transmitter')\n",
    "    prov.agent.append(prov_agent)\n",
    "    \n",
    "    prov_agent = P.ProvenanceAgent()\n",
    "    prov_agent.who = who_ref\n",
    "    prov_agent.type = get_agent_type(system='http://terminology.hl7.org/CodeSystem/provenance-participant-type',code='author')\n",
    "    prov.agent.append(prov_agent)\n",
    "    \n",
    "    #print(f'created resource Provenance-{prov.id} for resource {target_type}/{target_id}' )\n",
    "    \n",
    "    return(prov)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all entries and if US Core type change logical to literal reference and save\n",
    "\n",
    "#### Loop through entries and create literal to logical reference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meta(r):\n",
    "    \n",
    "    global r_list\n",
    "                          \n",
    "    t = r[\"resourceType\"]\n",
    "    i = r[\"id\"]\n",
    "    if t in types.keys(): \n",
    "       r_list.append(t)\n",
    "       if t not in [\"DiagnosticReport\",'Observation']: # add meta profiles\n",
    "           r['meta']= (dict(profile =[types[t]]))\n",
    "       elif \"Observation\" == t:  # \"Observation\"\n",
    "           try:\n",
    "               #['vital-signs','laboratory','72166-2']:\n",
    "               if 'laboratory' in r['category'][0]['coding'][0]['code']:\n",
    "                   r['meta']= dict(profile =[types[t][0]])\n",
    "               elif '72166-2' in r['code']['coding'][0]['code']:\n",
    "                   r['meta']= dict(profile =[types[t][2]])\n",
    "               elif '77606-2' in r['code']['coding'][0]['code']:\n",
    "                   r['meta']= dict(profile =[types[t][3]])\n",
    "               elif '59576-9' in r['code']['coding'][0]['code']:\n",
    "                   r['meta']= dict(profile =[types[t][4]])\n",
    "               elif '2708-6' in r['code']['coding'][0]['code']:\n",
    "                   r['meta']= dict(profile =[types[t][5]])\n",
    "               elif 'vital-signs' in r['category'][0]['coding'][0]['code']:\n",
    "                   r['meta']= dict(profile =[types[t][1]])\n",
    "               else: # use lab\n",
    "                   r['meta']= dict(profile =[types[t][0]])\n",
    "                   pass\n",
    "           except KeyError:\n",
    "                   r['meta']= dict(profile =[types[t][0]])\n",
    "\n",
    "       else:  # \"DiagnosticReport\"\n",
    "           try:\n",
    "               if 'LAB' in r['category'][0]['coding'][0]['code']:\n",
    "                   r['meta']= dict(profile =[types[t][0]])\n",
    "               elif r['category'][0]['coding'][0]['code'] in ['LP29684-5','LP29708-2','LP7839-6',]:\n",
    "                   r['meta']= dict(profile =[types[t][1]])\n",
    "               else:  # use lab\n",
    "                   r['meta']= dict(profile =[types[t][0]])\n",
    "                   pass\n",
    "           except KeyError:\n",
    "               r['meta']= dict(profile =[types[t][0]])\n",
    "                \n",
    "    '''\n",
    "    try:\n",
    "        print(f' update resource {t}-{i} with meta {r[\"meta\"][\"profile\"][0]}' )\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "    '''\n",
    "              \n",
    "    return(r)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Bundle entries using US Core Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_me(bundles):  ### Validate Bundle entries using US Core Validator\n",
    "    for b in bundles:\n",
    "        for e in b[\"entry\"]:\n",
    "                r = e[\"resource\"]\n",
    "                r_id = r[\"id\"]\n",
    "                #print(f'id = {r_id}')\n",
    "                t = r[\"resourceType\"]\n",
    "                #print(f'type = {t}')\n",
    "                # convert all logical to literal references\n",
    "                r_string = dumps(r,indent=4)\n",
    "                for ref_id, ref_type in ids.items(): \n",
    "                    r_string = r_string.replace(f'urn:uuid:{ref_id}',f'{ref_type}/{ref_id}')    \n",
    "                # validate using the validation build\n",
    "\n",
    "                write_file(r_string,t,r_id) # validate using the argovalidator (load to examples)\n",
    "    display(Markdown('**All files loaded onto Validator - run IG-Pub using -d option to validate**'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main File call all the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admit_type = {\n",
    "             \"coding\": [\n",
    "                        {\n",
    "                            \"code\": \"261665006\",\n",
    "                            \"display\": \"Unknown (qualifier value)\",\n",
    "                            \"system\": \"http://snomed.info/sct\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"text\": \"Unknown (qualifier value)\"\n",
    "                }\n",
    "\n",
    "td_type =  {\n",
    "            \"coding\": [\n",
    "                {\n",
    "                    \"code\": \"1234\",\n",
    "                    \"display\": \"Examplotomy Encounter\",\n",
    "                    \"system\": \"http://snomed.info/sct\"\n",
    "                }\n",
    "            ],\n",
    "            \"text\": \"Examplotomy Encounter\"\n",
    "        }\n",
    "\n",
    "transfer_code = dict(\n",
    "    system = \"http://terminology.hl7.org/CodeSystem/admit-source\",\n",
    "    code = \"transfer\",\n",
    "    display = \"Transfer\",\n",
    "    )\n",
    "\n",
    "transfer = dict(\n",
    "       text = \"Transfer\",\n",
    "       coding = [transfer_code],\n",
    "       )\n",
    "\n",
    "pat_identifier_map = {}\n",
    "clear_path()\n",
    "r_list= []\n",
    "new_b= dict(\n",
    "    type = \"transaction\",\n",
    "    resourceType =\"Bundle\",\n",
    "    entry = []\n",
    ")\n",
    "\n",
    "synthea_files = [f_name] if f_name else [i for i in listdir(in_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_request(t,method,r_id):                   \n",
    "    req = dict(\n",
    "        method = method,\n",
    "        url = f'{t}/{r_id}'\n",
    "          )\n",
    "    return(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_refs(e):\n",
    "\n",
    "   loc_ref = e['resource']['location'][0]['location']['reference']\n",
    "   loc_ref = loc_ref.replace(\"urn:uuid:\",'Location/')\n",
    "   e['resource']['location'][0]['location']['reference']=loc_ref\n",
    " \n",
    "   sub_ref = e['resource']['subject']['reference']\n",
    "   sub_ref = sub_ref.replace(\"urn:uuid:\",'Patient/')\n",
    "   e['resource']['subject']['reference'] = sub_ref\n",
    "\n",
    "   pract_ref = e['resource']['participant'][0]['individual']['reference']\n",
    "   pract_ref = pract_ref.replace(\"urn:uuid:\",'Practitioner/')\n",
    "   e['resource']['participant'][0]['individual']['reference'] = pract_ref\n",
    "    \n",
    "   org_ref = e['resource']['serviceProvider']['reference']\n",
    "   org_ref = org_ref.replace(\"urn:uuid:\",'Organization/')\n",
    "   e['resource']['serviceProvider']['reference'] = org_ref\n",
    "\n",
    "   return(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix encounter references to same make encounter ID dict\n",
    "b = open_file(in_path,f_name)\n",
    "enc_map = {e[\"resource\"]['subject']['reference']:e[\"resource\"][\"id\"] \n",
    "           for e in b[\"entry\"] if e[\"resource\"]['resourceType'] == \"Encounter\" \n",
    "           and e[\"resource\"][\"class\"][\"code\"]==\"EMER\"}\n",
    "\n",
    "\n",
    "\n",
    "enc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in synthea_files: # assume is synthea patient bundle.\n",
    "    print(file)\n",
    "    ids = {}\n",
    "    provs = []\n",
    "    if file.endswith(\".json\"):\n",
    "        print(\"json file found:\\t\", file)\n",
    "        b = open_file(in_path,file)\n",
    "        admit_b = deepcopy(new_b)\n",
    "        transfer_b = deepcopy(new_b)\n",
    "        discharge_b = deepcopy(new_b)\n",
    "        print(f'bundle length = {len(b[\"entry\"])}')\n",
    "        #org_id = prefetch_org(b) # for provenance\n",
    "        #print(f'Provenance Organization url will be: Organization/{org_id}')\n",
    "           \n",
    "        \n",
    "        for i, e in enumerate(b[\"entry\"]): # fix admit and save identifiers\n",
    "            r = e[\"resource\"]\n",
    "            r_id = r[\"id\"]\n",
    "            t = r[\"resourceType\"]\n",
    "            e[\"request\"] = t_request(t,\"PUT\",r_id)\n",
    "            if t == 'Encounter':\n",
    "                print(i,r['resourceType'] )\n",
    "                print(r[\"class\"][\"code\"])\n",
    "                try:  # fix admit and add transfer\n",
    "                    if r['hospitalization']['dischargeDisposition']:\n",
    "                        print(\"*\"* 10,\"DICHARGE\",\"*\"* 10 ) \n",
    "                except KeyError:\n",
    "                   print(\"*\"* 10,\"ADMIT\",\"*\"* 10 ) \n",
    "                   print(f'class should be \"EMER\" is listed as {r[\"class\"][\"code\"]}')\n",
    "                   print(f'status should be \"in-progress\" is listed as {r[\"status\"]}')\n",
    "                   print(f'type should be \"unknown\" is listed as {r[\"type\"][0][\"text\"]}')\n",
    "                   r['status'] = \"in-progress\"\n",
    "                   r[\"type\"] = [admit_type]\n",
    "                   print(f'class should be \"EMER\" is listed as {r[\"class\"][\"code\"]}')\n",
    "                   print(f'status should be \"in-progress\" is now  listed as {r[\"status\"]}')\n",
    "                   print(f'type should be \"unknown\" is now listed as {r[\"type\"][0][\"text\"]}')\n",
    "                   #update identifier and create mapping\n",
    "                   smush_name = ''.join(r['subject']['display'].split()[1:])\n",
    "                   smush_date = r['period']['start'].replace('-','').replace(':','')\n",
    "                   pat_identifier_map[r['subject']['display']] = f\"{smush_name}{smush_date}\"\n",
    "                   #print(smush_name, smush_date)\n",
    "                   enc_identifier = dict(\n",
    "                       system = \"http://example.org\",\n",
    "                       value = pat_identifier_map[r['subject']['display']]\n",
    "                   )\n",
    "                   r['identifier']=[enc_identifier]\n",
    "                   print(f\"identifier should be {pat_identifier_map[r['subject']['display']]} is now listed as {r['identifier'][0]['value']}\")\n",
    "                   admit_b['entry'].append(e)\n",
    "                   print(f'admit bundle length = {len(admit_b[\"entry\"])}')\n",
    "                   print(f'discharge bundle length = {len(discharge_b[\"entry\"])}')\n",
    "                   print(f'transfer bundle length = {len(transfer_b[\"entry\"])}....end Admit')\n",
    "\n",
    "\n",
    "                   # add transfer to new bundle\n",
    "                   print(\"*\"* 10,\"TRANSFER\",\"*\"* 10 )\n",
    "                   t_entry = deepcopy(e)\n",
    "                   print(f\"fullUrl should be { t_entry['fullUrl']}\")\n",
    "                   #t_entry['resource']['id'] = t_uuid\n",
    "                   t_entry['resource'][\"class\"][\"code\"] = \"IMP\"\n",
    "                   t_entry['resource'][\"type\"] = [td_type]\n",
    "                   print(f'type should be \"examplitis\" is now listed as {r[\"type\"][0][\"text\"]}')\n",
    "                   t_entry['resource'][\"hospitalization\"] = dict(\n",
    "                       admitSource = transfer,\n",
    "                       )\n",
    "\n",
    "                   print(f\"hospitalization should be 'TRANSFER' is now listed as {t_entry['resource']['hospitalization']['admitSource']['text']}\")\n",
    "                   t_entry = update_refs(t_entry)\n",
    "                   transfer_b['entry'].append(t_entry)\n",
    "                   print(f'admit bundle length = {len(admit_b[\"entry\"])}')\n",
    "                   print(f'discharge bundle length = {len(discharge_b[\"entry\"])}')\n",
    "                   print(f'transfer bundle length = {len(transfer_b[\"entry\"])}....end Transfer')\n",
    "\n",
    "\n",
    "                else: # update discharge and remove to discharge bundle\n",
    "                    #update the id\n",
    "                    for k,v in enc_map.items():\n",
    "                        if r['subject']['reference'] == k:\n",
    "                            print(f\"discharge matches patients {k}\")\n",
    "                            r['id'] = v\n",
    "                            e['fullUrl'] = f\"urn:uuid:{v}\"\n",
    "                            e[\"request\"] = t_request(t,\"PUT\",v)\n",
    "                            print(f\"discharge matches patients {k} id = {r['id']} and fullUrl = {e['fullUrl']}\")\n",
    "                    print(f'status should be \"finished\" is listed as {r[\"status\"]}')\n",
    "                    print(f'type should be \"examplitis\" is listed as {r[\"type\"][0][\"text\"]}')\n",
    "                    print(f'class should be \"IMP\" is listed as {r[\"class\"][\"code\"]}')\n",
    "                    r['status'] = \"finished\"\n",
    "                    r[\"type\"] = [td_type]\n",
    "                    r[\"class\"][\"code\"] = \"IMP\"\n",
    "                    print(f'status should be \"finished\" is now listed as {r[\"status\"]}')\n",
    "                    print(f'type should be \"examplitis\" is now listed as {r[\"type\"][0][\"text\"]}')\n",
    "                    print(f'class should be \"IMP\" is listed as {r[\"class\"][\"code\"]}')\n",
    "                    #update identifier and create mapping\n",
    "                    smush_name = ''.join(r['subject']['display'].split()[1:])\n",
    "                    smush_date = r['period']['start'].replace('-','').replace(':','')\n",
    "                    pat_identifier_map[r['subject']['display']] = f\"{smush_name}{smush_date}\"\n",
    "                    enc_identifier = dict(\n",
    "                               system = \"http://example.org\",\n",
    "                               value = pat_identifier_map[r['subject']['display']]\n",
    "                           )\n",
    "                    r['identifier']=[enc_identifier]\n",
    "                    print(f\"identifier should be {pat_identifier_map[r['subject']['display']]} is now listed as {r['identifier'][0]['value']}\")\n",
    "                    entry = update_refs(e)\n",
    "                    discharge_b['entry'].append(e)\n",
    "                    print(f'admit bundle length = {len(admit_b[\"entry\"])}')\n",
    "                    print(f'discharge bundle length = {len(discharge_b[\"entry\"])}')\n",
    "                    print(f'transfer bundle length = {len(transfer_b[\"entry\"])}....end Discharge')\n",
    "\n",
    "                # remove condition from admit bundle and add to discharge bundle              \n",
    "            elif t == 'Condition':\n",
    "               for k,v in enc_map.items():  # Update references\n",
    "                    if r['subject']['reference'] == k:\n",
    "                        r['subject']['reference'] = k.replace(\"urn:uuid:\",'Patient/')\n",
    "                        r['encounter']['reference'] = f\"urn:uuid:{v}\"\n",
    "               transfer_b['entry'].append(e)\n",
    "               print(f'transfer bundle length = {len(transfer_b[\"entry\"])}....end add Condition')\n",
    "            else:\n",
    "                admit_b['entry'].append(e)\n",
    "                print(f'admit bundle length = {len(admit_b[\"entry\"])}....end add else = {t}')\n",
    "            \n",
    "               \n",
    "            '''\n",
    "            if t in types.keys(): # see what types are in bundle\n",
    "               r_list.append(t)\n",
    "            # get a list of id's to create literal references later using a string replace \n",
    "            ids[r_id]=t\n",
    "            \n",
    "            #e['resource']= add_meta(r) # add meta elements to resource  - Synthea already does this!!!\n",
    "            \n",
    "            #change POST to PUT and update the URL\n",
    "            e['request']['method']='PUT'\n",
    "            e['request']['url']=f'{e[\"request\"][\"url\"]}/{r_id}'\n",
    "            \n",
    "            # create provenance and add to list\n",
    "            provs.append(get_prov(org_id,t,r_id)) #create corresponding Provenance resource and add to list\n",
    "            '''\n",
    "            \n",
    "        '''\n",
    "        # create a transaction bundle provenance ,stick with dict type\n",
    "        pb = dict(\n",
    "            resourceType=\"Bundle\",\n",
    "            type=\"transaction\",\n",
    "            )\n",
    "        \n",
    "        pb['entry'] = []\n",
    "        for p in provs:\n",
    "            ids[p.id]='Provenance'\n",
    "            \n",
    "            e = dict( # no fullURL for now - use relative literal references\n",
    "                resource = p.as_json(),\n",
    "                request = dict(\n",
    "                    method='PUT',\n",
    "                    url= f'Provenance/{p.id}',\n",
    "                    ), \n",
    "                )\n",
    "            \n",
    "            pb['entry'].append(e)\n",
    "            \n",
    "          \n",
    "        '''\n",
    "        \n",
    "        #write bundles to temp file to test manually\n",
    "        #for i, bundle in enumerate([pb,b]):\n",
    "        #print(len(b['entry']),len(new_b),len(b['entry'] + new_b))\n",
    "        \n",
    "        for use in (['admit','transfer','discharge']):\n",
    "            d_bundle = eval(f'{use}_b')\n",
    "            #list_FullUrls = [(e['resource']['resourceType'],e['fullUrl']) for e in d_bundle['entry']]\n",
    "            #pprint(list_FullUrls)\n",
    "            #pprint([i for i, x in enumerate(list_FullUrls) if list_FullUrls.count(x) > 1])\n",
    "            j_bundle = dumps(d_bundle, indent=4)\n",
    "            with open(f'{out_path}/{use}_{f_name}', 'w') as f:\n",
    "                f.write(j_bundle)\n",
    "         \n",
    "        \n",
    "            print(f'*********validate {use} bundle using the validation build ********')\n",
    "            r = validate(j_bundle)\n",
    "            display(HTML('<h1>Request Headers</h1>'))\n",
    "            pprint(r.request.headers)\n",
    "            display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "\n",
    "\n",
    "            print(f'*********load {use} bundle to FHIR Server ***********')\n",
    "            r = post_transaction(j_bundle)\n",
    "            display(HTML('<h1>Request Headers</h1>'))\n",
    "            pprint(r.request.headers)\n",
    "            #display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "            display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3>'))\n",
    "            pprint(r.json())\n",
    "            sleep(5)\n",
    "            \n",
    "         \n",
    "            '''print(f'*********Optional delete {use} bundle using the validation build ********')\n",
    "            for e in d_bundle['entry']:\n",
    "                t = e['resource']['resourceType']\n",
    "                r_id = e['resource']['id']\n",
    "                #print(t, r_id)\n",
    "                r = delete_r(t,r_id)\n",
    "                display(HTML('<h1>Request Headers</h1>'))\n",
    "                pprint(r.request.headers)\n",
    "                #display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "                display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3>'))\n",
    "                pprint(r.json())\n",
    "           '''\n",
    "\n",
    "print('======Fin======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
