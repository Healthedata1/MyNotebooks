{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FHIR R4 SearchParameter Resource\n",
    "\n",
    "Create FHIR R4 SearchParameter Resource, Quick start text, and Searchparameter list using the python fhir client\n",
    "\n",
    "Source data is in excel file\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Python 3.7 or greater\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FHIRR4Client and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhirclient.r4models.fhirabstractbase import FHIRValidationError\n",
    "from fhirclient.r4models import searchparameter as SP\n",
    "from fhirclient.r4models import capabilitystatement as CS\n",
    "from fhirclient.r4models import bundle as B\n",
    "from fhirclient.r4models import narrative as N\n",
    "import fhirclient.r4models.identifier as I\n",
    "import fhirclient.r4models.coding as C\n",
    "import fhirclient.r4models.codeableconcept as CC\n",
    "import fhirclient.r4models.fhirdate as D\n",
    "import fhirclient.r4models.extension as X\n",
    "import fhirclient.r4models.contactdetail as CD\n",
    "from json import dumps, loads, load\n",
    "from requests import get, post, put\n",
    "import os\n",
    "from pathlib import Path\n",
    "from csv import reader as csvreader\n",
    "from IPython.display import display as Display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "from pandas import *\n",
    "from datetime import datetime\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "import R4sp_summary_list as sp_map\n",
    "from stringcase import snakecase, titlecase, pascalcase\n",
    "from itertools import zip_longest\n",
    "from openpyxl import load_workbook\n",
    "import R4sp_summary_list as sp_map\n",
    "from itertools import zip_longest\n",
    "from openpyxl import load_workbook\n",
    "from lxml import etree\n",
    "from commonmark import commonmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Assign Global Variables\n",
    "\n",
    "\n",
    "Here is where we assign all the global variables for this example such as the local paths for file input and output\n",
    "\n",
    "##### Need to update:\n",
    "- base_id\n",
    "- paths\n",
    "- canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** Need to update for each IG *************************************************\n",
    "fhir_base_url = 'http://hl7.org/fhir/R4/'\n",
    "base_id = \"US-Core\"\n",
    "canon_base = \"http://hl7.org/fhir/us/core/\"\n",
    "ig_folder = 'US-Core-R4'\n",
    "publisher = 'HL7 International - US Realm Steering Committee'\n",
    "publisher_endpoint = dict(\n",
    "                        system = 'url',\n",
    "                        value = 'http://www.hl7.org/Special/committees/usrealm/index.cfm'\n",
    "                        ) \n",
    "\n",
    "#ig_source_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/input/\"  # for pc\n",
    "ig_source_path = \"/Users/ehaas/Documents/FHIR/US-Core-R4/input/\"    # for mac\n",
    "\n",
    "write_path = '' # temp path\n",
    "\n",
    "\n",
    "#spdef_json = 'C:/Users/Eric/Documents/HL7/FHIR/BUILD_EDIT_FILES/R4_Definitions/search-parameters.json'\n",
    "#spdef_json ='/Users/ehaas/Downloads/definitionsR4.json/search-parameters.json' # v  4.0.1\n",
    "spdef_json = 'sp_defs_4.0.1.json'  #v 4.0.1 does not have mods!! use this for v4\n",
    "\n",
    "skip_types = ['Questionnaire',]\n",
    "\n",
    "### limit to these profiles ( DOES NOT WORK If >1 Profile of same TYPE - Comment out to do  Quick starts for all profiles ####\n",
    "whitelist = ['http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitioner',] #['http://hl7.org/fhir/us/core/StructureDefinition/us-core-organization',] #'http://hl7.org/fhir/us/core/StructureDefinition/us-core-diagnosticreport-note']\n",
    "\n",
    "validate_flag = True\n",
    "#***********************************************************************************\n",
    "\n",
    "def markdown(text, *args, **kwargs):\n",
    "    return commonmark(text, *args, **kwargs)\n",
    "\n",
    "env = Environment(\n",
    "    loader=FileSystemLoader(searchpath = ''),\n",
    "    autoescape=select_autoescape(['html','xml','xhtml','j2','md'])\n",
    "    )\n",
    "\n",
    "\n",
    "env.filters['markdown'] = markdown\n",
    "\n",
    "\n",
    "\n",
    "md_template = ['quick_start.j2', 'sp_list_page.j2', 'cs_search_documentation.j2','sp_narrative.j2']\n",
    "\n",
    "\n",
    "fhir_term_server = 'http://test.fhir.org/r4'\n",
    "\n",
    "#profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    "\n",
    "\n",
    "none_list = ['', ' ', 'none', 'n/a', 'N/A', 'N', 'False', 'FALSE']\n",
    "sep_list = (',', ';', ' ', ', ', '; ')\n",
    "custom_sp = ['race','ethnicity','gender-identity','asserted-date','discharge-disposition','role']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " def write_file(path,name,data): # write file\n",
    "    with open(f'{write_path}{path}{name}', 'w', newline='\\n') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** validate Resource as Dict ********************************\n",
    "\n",
    "def validate(r):\n",
    "\n",
    "    fhir_test_server = 'http://test.fhir.org/r4'\n",
    "\n",
    "    headers = {\n",
    "    'Accept':'application/fhir+json',\n",
    "    'Content-Type':'application/fhir+json'\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "    }\n",
    "    \n",
    "    r = post(f'{fhir_test_server}/{r[\"resourceType\"]}/$validate', params = params, headers = headers, data = dumps(r))\n",
    "    # return r.status_code\n",
    "    # view  output\n",
    "    # return (r.json()[\"text\"][\"div\"])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Search Parameter input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>base</th>\n",
       "      <th>profile</th>\n",
       "      <th>combo</th>\n",
       "      <th>is_new</th>\n",
       "      <th>combo_conf</th>\n",
       "      <th>types</th>\n",
       "      <th>fixed_kv</th>\n",
       "      <th>description</th>\n",
       "      <th>example</th>\n",
       "      <th>imp_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>!Encounter</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>class,date</td>\n",
       "      <td></td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>date,token</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Fetches a bundle of all !Encounter resources m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>!Encounter</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>class,date,patient</td>\n",
       "      <td></td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>date,reference,token</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Fetches a bundle of all !Encounter resources m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>!Encounter</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>class,date,patient,type</td>\n",
       "      <td></td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>date,reference,token</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Fetches a bundle of all !Encounter resources m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>!Encounter</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>class,date,type</td>\n",
       "      <td></td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>date,token</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Fetches a bundle of all !Encounter resources m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Encounter</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>class,patient</td>\n",
       "      <td></td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>reference,token</td>\n",
       "      <td></td>\n",
       "      <td>support searching for all encounter for a pati...</td>\n",
       "      <td>GET [base]/Encounter?patient=example1&amp;class= h...</td>\n",
       "      <td>Fetches a bundle of all Encounter resources ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>110</td>\n",
       "      <td>DocumentReference</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>patient,category,date</td>\n",
       "      <td></td>\n",
       "      <td>SHALL</td>\n",
       "      <td>reference,token,date</td>\n",
       "      <td>category=http://hl7.org/fhir/us/core/CodeSyste...</td>\n",
       "      <td>support searching for all clinical notes for a...</td>\n",
       "      <td>GET [base]/DocumentReference?patient=1235541&amp;c...</td>\n",
       "      <td>Fetches a bundle of all DocumentReference reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>111</td>\n",
       "      <td>DocumentReference</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>patient,type</td>\n",
       "      <td></td>\n",
       "      <td>SHALL</td>\n",
       "      <td>reference,token</td>\n",
       "      <td></td>\n",
       "      <td>support searching for a specific note type for...</td>\n",
       "      <td>GET [base]/DocumentReference?patient=1316024&amp;t...</td>\n",
       "      <td>Fetches a bundle of all DocumentReference reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>112</td>\n",
       "      <td>DocumentReference</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>patient,type,period</td>\n",
       "      <td></td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>reference,token,date</td>\n",
       "      <td></td>\n",
       "      <td>support searching for a document for a patient...</td>\n",
       "      <td>GET [base]/DocumentReference?patient=2169591&amp;t...</td>\n",
       "      <td>Fetches a bundle of all DocumentReference reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>115</td>\n",
       "      <td>Device</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>patient,type</td>\n",
       "      <td></td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>reference,token</td>\n",
       "      <td></td>\n",
       "      <td>support searching for a specific device type f...</td>\n",
       "      <td>GET [base]/Device?patient=1316024&amp;type=http://...</td>\n",
       "      <td>Fetches a bundle of all Device resources for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>94</td>\n",
       "      <td>CareTeam</td>\n",
       "      <td>http://hl7.org/fhir/us/core/StructureDefinitio...</td>\n",
       "      <td>patient,role</td>\n",
       "      <td>True</td>\n",
       "      <td>SHOULD</td>\n",
       "      <td>reference,token</td>\n",
       "      <td></td>\n",
       "      <td>support searching for all current care team me...</td>\n",
       "      <td>GET [base]/CareTeam?patient=1137192&amp;role=http:...</td>\n",
       "      <td>Fetches a bundle of all CareTeam resources for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index               base  \\\n",
       "0       1         !Encounter   \n",
       "1       2         !Encounter   \n",
       "2       3         !Encounter   \n",
       "3       4         !Encounter   \n",
       "4       5          Encounter   \n",
       "..    ...                ...   \n",
       "85    110  DocumentReference   \n",
       "86    111  DocumentReference   \n",
       "87    112  DocumentReference   \n",
       "88    115             Device   \n",
       "89     94           CareTeam   \n",
       "\n",
       "                                              profile  \\\n",
       "0   http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "1   http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "2   http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "3   http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "4   http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "..                                                ...   \n",
       "85  http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "86  http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "87  http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "88  http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "89  http://hl7.org/fhir/us/core/StructureDefinitio...   \n",
       "\n",
       "                      combo is_new combo_conf                 types  \\\n",
       "0                class,date            SHOULD            date,token   \n",
       "1        class,date,patient            SHOULD  date,reference,token   \n",
       "2   class,date,patient,type            SHOULD  date,reference,token   \n",
       "3           class,date,type            SHOULD            date,token   \n",
       "4             class,patient            SHOULD       reference,token   \n",
       "..                      ...    ...        ...                   ...   \n",
       "85    patient,category,date             SHALL  reference,token,date   \n",
       "86             patient,type             SHALL       reference,token   \n",
       "87      patient,type,period            SHOULD  reference,token,date   \n",
       "88             patient,type            SHOULD       reference,token   \n",
       "89             patient,role   True     SHOULD       reference,token   \n",
       "\n",
       "                                             fixed_kv  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "85  category=http://hl7.org/fhir/us/core/CodeSyste...   \n",
       "86                                                      \n",
       "87                                                      \n",
       "88                                                      \n",
       "89                                                      \n",
       "\n",
       "                                          description  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4   support searching for all encounter for a pati...   \n",
       "..                                                ...   \n",
       "85  support searching for all clinical notes for a...   \n",
       "86  support searching for a specific note type for...   \n",
       "87  support searching for a document for a patient...   \n",
       "88  support searching for a specific device type f...   \n",
       "89  support searching for all current care team me...   \n",
       "\n",
       "                                              example  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4   GET [base]/Encounter?patient=example1&class= h...   \n",
       "..                                                ...   \n",
       "85  GET [base]/DocumentReference?patient=1235541&c...   \n",
       "86  GET [base]/DocumentReference?patient=1316024&t...   \n",
       "87  GET [base]/DocumentReference?patient=2169591&t...   \n",
       "88  GET [base]/Device?patient=1316024&type=http://...   \n",
       "89  GET [base]/CareTeam?patient=1137192&role=http:...   \n",
       "\n",
       "                                             imp_note  \n",
       "0   Fetches a bundle of all !Encounter resources m...  \n",
       "1   Fetches a bundle of all !Encounter resources m...  \n",
       "2   Fetches a bundle of all !Encounter resources m...  \n",
       "3   Fetches a bundle of all !Encounter resources m...  \n",
       "4   Fetches a bundle of all Encounter resources ma...  \n",
       "..                                                ...  \n",
       "85  Fetches a bundle of all DocumentReference reso...  \n",
       "86  Fetches a bundle of all DocumentReference reso...  \n",
       "87  Fetches a bundle of all DocumentReference reso...  \n",
       "88  Fetches a bundle of all Device resources for t...  \n",
       "89  Fetches a bundle of all CareTeam resources for...  \n",
       "\n",
       "[90 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path = f\"{ig_source_path}resources_spreadsheets/\"\n",
    "#in_path =''\n",
    "\n",
    "in_file =\"uscore-server\"\n",
    "\n",
    "xls = ExcelFile(f'{in_path}{in_file}.xlsx')\n",
    "df = read_excel(xls,'sps',na_filter = False)\n",
    "df_combos = read_excel(xls,'sp_combos',na_filter = False)\n",
    "\n",
    "df_combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defin SPs and Combos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource = Practitioner, Search Parameter = _id, Exists = Y\n",
      "Resource = Practitioner, Search Parameter = name, Exists = Y\n",
      "Resource = Practitioner, Search Parameter = identifier, Exists = Y\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = [i for i in df.itertuples(index=True) \n",
    "                  if '!' not in i.base and i.profile in whitelist]\n",
    "    combo_data = [i for i in df_combos.itertuples(index=True)\n",
    "                  if '!' not in i.base and i.profile in whitelist]\n",
    "except NameError:\n",
    "    data = [i for i in df.itertuples(index=True) if '!' not in i.base]\n",
    "    combo_data = [i for i in df_combos.itertuples(index=True) if '!' not in i.base]\n",
    "    \n",
    "r_type =  {d.base for d in data }\n",
    "\n",
    "search_profiles = {i.profile:i.base for i in combo_data}\n",
    "\n",
    "for d in data:\n",
    "    print(f'Resource = {d.base}, Search Parameter = {d.code}, Exists = {d.exists}')\n",
    "for c in combo_data:\n",
    "    print(f'Resource = {c.base}, Combo Search Parameter = {c.combo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update core SP with additional capabiliities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Get definitions bundle and convert to python object for ease of notation\n",
    "- use sp_map to map to Type + parameter\n",
    "- If need to update SP Extract the SP based on the excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load SP Mapping dictionary\n",
    "\n",
    "output shows a single SP entry for a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"Resource-id\",\n",
      "    \"extension\": [\n",
      "        {\n",
      "            \"url\": \"http://hl7.org/fhir/StructureDefinition/structuredefinition-standards-status\",\n",
      "            \"valueCode\": \"trial-use\"\n",
      "        }\n",
      "    ],\n",
      "    \"base\": [\n",
      "        \"Resource\"\n",
      "    ],\n",
      "    \"code\": \"_id\",\n",
      "    \"contact\": [\n",
      "        {\n",
      "            \"telecom\": [\n",
      "                {\n",
      "                    \"system\": \"url\",\n",
      "                    \"value\": \"http://hl7.org/fhir\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"telecom\": [\n",
      "                {\n",
      "                    \"system\": \"url\",\n",
      "                    \"value\": \"http://www.hl7.org/Special/committees/fiwg/index.cfm\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"date\": \"2019-11-01T09:29:23+11:00\",\n",
      "    \"description\": \"Logical id of this artifact\",\n",
      "    \"experimental\": false,\n",
      "    \"expression\": \"Resource.id\",\n",
      "    \"name\": \"_id\",\n",
      "    \"publisher\": \"Health Level Seven International (FHIR Infrastructure)\",\n",
      "    \"status\": \"draft\",\n",
      "    \"type\": \"token\",\n",
      "    \"url\": \"http://hl7.org/fhir/SearchParameter/Resource-id\",\n",
      "    \"version\": \"4.0.1\",\n",
      "    \"xpath\": \"f:Resource/f:id\",\n",
      "    \"xpathUsage\": \"normal\",\n",
      "    \"resourceType\": \"SearchParameter\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "p = Path(spdef_json)\n",
    "b = B.Bundle(loads(p.read_text()), strict = False)\n",
    "test_sp = next(i.resource for i in b.entry if i.resource.url == 'http://hl7.org/fhir/SearchParameter/Resource-id')\n",
    "\n",
    "'''\n",
    "for i in b.entry:\n",
    "    if 'clinical-patient' in i.resource.id:\n",
    "          print(dumps(i.resource.as_json(), indent=4))\n",
    "'''\n",
    "print(dumps(test_sp.as_json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create updated SPs\n",
    "- sp optional 'modifier' elements are listed as comma separated list of shalls and shoulds for each:\n",
    "- multipleOr\n",
    "- multipleOr_conf\n",
    "- multipleAnd\n",
    "- multipleAnd_conf\n",
    "- shall_modifier\n",
    "- should_modifier\n",
    "- shall_comparator\n",
    "- should_comparator\n",
    "- shall_chain\n",
    "\n",
    " if not spedified then conformance is MAY \n",
    "\n",
    "- note that it starts out using the FHIRClient models but the switches to a dict structure to add the FHIR primitive type extensions.*\n",
    "\n",
    "- create a nice XHTML narrative without spaces\n",
    "   - stick the div in the body\n",
    "   - the declaration must be  `<?xml version=\"1.0\"?>`  and not `<?xml version=\"1.0\" encoding=\"UTF-8\"?>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_expectation(conf=None):\n",
    "    if not conf:\n",
    "        conf = \"MAY\"\n",
    " \n",
    "    x = X.Extension(dict(\n",
    "    url = f'http://hl7.org/fhir/StructureDefinition/capabilitystatement-expectation',\n",
    "    valueCode = conf\n",
    "    ))\n",
    "    x_dict = dict(\n",
    "    extension = [x.as_json()]\n",
    "    ) \n",
    "    return x_dict\n",
    "\n",
    "def find_base_sp(d):\n",
    "    if '!' not in d.base and d.update =='Y':\n",
    "        print(d.base, d.code)\n",
    "        if d.code in custom_sp:\n",
    "            print(f\"{d.base} {d.code} is Custom SP!!\")\n",
    "            return\n",
    "        \n",
    "        elif d.code == '_id':\n",
    "            sp = next(i.resource for i in b.entry if i.resource.url == 'http://hl7.org/fhir/SearchParameter/Resource-id')\n",
    "            sp = SP.SearchParameter(sp.as_json())\n",
    "            sp.expression = f'{d.base}.{d.code.replace(\"_\",\"\")}'\n",
    "            sp.xpath  = f'f:{d.base}/f:{d.code.replace(\"_\",\"\")}'\n",
    "            print(f'sp.expression = {sp.expression}')\n",
    "        \n",
    "        else:\n",
    "            sp = next(i.resource for i in b.entry if i.resource.code == d.code and d.base in i.resource.base)       \n",
    "            sp = SP.SearchParameter(sp.as_json())\n",
    "            #print(sp.description)\n",
    "        return sp\n",
    "    \n",
    "def kebab_to_pascal(word):\n",
    "    return ''.join(x.capitalize() for x in word.split('-'))\n",
    "\n",
    "expect_note = '''\n",
    "**NOTE**: This US Core SearchParameter definition extends the usage context of the\n",
    "[Conformance expectation extension](http://hl7.org/fhir/R4/extension-capabilitystatement-expectation.html)\n",
    " - multipleAnd\n",
    " - multipleOr\n",
    " - comparator\n",
    " - modifier\n",
    " - chain'''\n",
    "\n",
    "sp_list=[]\n",
    "\n",
    "\n",
    "for d in data:\n",
    "        print(f'========={d.base},{d.code}==============')\n",
    "        sp = find_base_sp(d)\n",
    "        \n",
    "        #print(type(sp))\n",
    "        if sp:\n",
    "            #print(sp.url)\n",
    "            # change id and url, publisher, and contact, draft etc\n",
    "            sp.id = f'{base_id.lower()}-{d.base.lower()}-{d.code.replace(\"_\",\"\")}'  \n",
    "            sp.extension = []\n",
    "            sp.derivedFrom =sp.url\n",
    "            sp.url = f'{canon_base}SearchParameter/{sp.id}'\n",
    "            sp.publisher = publisher\n",
    "            sp.contact = [CD.ContactDetail( {\"telecom\" : [ publisher_endpoint ] })]\n",
    "            sp.date = D.FHIRDate(f'{datetime.utcnow().isoformat()}Z')\n",
    "            sp.name = kebab_to_pascal(sp.id)\n",
    "            sp.name = sp.name.replace('UsCore','USCore')\n",
    "            sp.status = 'active'\n",
    "            sp.base = [d.base]\n",
    " \n",
    "            # need to check this code for all SP's \n",
    "            print(f'sp.expression={sp.expression}')\n",
    "            #my_expression = [i.strip('(').strip(')').strip() for i in sp.expression.split('|') if i.strip('(').strip(')').strip().startswith(f'{d.base}.')]\n",
    "            my_expression = [i.strip() for i in sp.expression.split('|') if i.strip().startswith(f'{d.base}.')]\n",
    "            sp.expression = '|'.join(my_expression)\n",
    "            \n",
    "            print(f'sp.xpath={sp.xpath}')\n",
    "            my_xpath = [i.strip() for i in sp.xpath.split('|') if i.strip().startswith(f'f:{d.base}/')]\n",
    " \n",
    "            sp.xpath = '|'.join(my_xpath)  \n",
    "            #print(\"---\", sp.description)\n",
    "            my_description = [i.strip() for i in sp.description.split('\\r\\n* ') if i.strip().startswith(f'[{d.base}]')]\n",
    "            my_description = [i.split(\":\")[-1] for i in my_description]         \n",
    "            #print(\"---\",my_description)\n",
    "            if my_description:\n",
    "                sp.description = ''.join(my_description)\n",
    "            #else:\n",
    "                #print(\"---\",sp.description)\n",
    "            #except IndexError:   \n",
    "                #print(sp.expression)\n",
    "            sp.description = f'**{sp.description.strip()}**  {expect_note}'\n",
    "            #print(sp.description)\n",
    "            display(Markdown(sp.description))\n",
    "\n",
    "            \n",
    "\n",
    "  \n",
    "\n",
    "            #convert to dict since model can't handle primitive extensions\n",
    "            sp_dict = sp.as_json()\n",
    "\n",
    "            sp_dict['multipleOr'] = False if d.multipleOr in none_list else True\n",
    "            sp_dict['_multipleOr'] = sp_expectation(d.multipleOr_conf)\n",
    "            \n",
    "            sp_dict['multipleAnd'] = False if d.multipleAnd in none_list else True\n",
    "            sp_dict['_multipleAnd'] = sp_expectation(d.multipleAnd_conf)\n",
    "            \n",
    "            try:\n",
    "                sp_dict['_modifier'] = []\n",
    "                for m in sp_dict['modifier']: # list all modifiers in sp and assign an expectation.\n",
    "                    if d.shall_modifier not in none_list and m in d.shall_modifier.split(','):\n",
    "                       sp_dict['_modifier'].append(sp_expectation('SHALL'))\n",
    "                    elif  d.should_modifier not in none_list and m in d.should_modifier.split(','):\n",
    "                        sp_dict['_modifier'].append(sp_expectation('SHOULD'))               \n",
    "                    else:\n",
    "                        sp_dict['_modifier'].append(sp_expectation('MAY'))\n",
    "            except KeyError:\n",
    "                del(sp_dict['_modifier'])\n",
    "\n",
    "            try:\n",
    "                sp_dict['_comparator'] = []\n",
    "                for m in sp_dict['comparator']: # list all comparators in sp and assign an expectation.\n",
    "                   if d.shall_comparator not in none_list and m in d.shall_comparator.split(','):\n",
    "                       sp_dict['_comparator'].append(sp_expectation('SHALL'))\n",
    "                   elif  d.should_comparator not in none_list and m in d.should_comparator.split(','):\n",
    "                        sp_dict['_comparator'].append(sp_expectation('SHOULD'))               \n",
    "                   else:\n",
    "                        sp_dict['_comparator'].append(sp_expectation('MAY'))\n",
    "            except KeyError:\n",
    "                del(sp_dict['_comparator'])\n",
    "\n",
    "            if d.shall_chain not in none_list:\n",
    "               sp_dict['chain'] = d.shall_chain.split(',')\n",
    "               sp_dict['_chain'] = [sp_expectation('SHALL') for c in d.shall_chain.split(',')]\n",
    "\n",
    "            if d.should_chain not in none_list:\n",
    "               sp_dict['chain'] = d.should_chain.split(',')\n",
    "               sp_dict['_chain'] = [sp_expectation('SHALL') for c in d.should_chain.split(',')]\n",
    "\n",
    "            print(f'======================= SP = {sp_dict[\"id\"]} =====================')\n",
    "            #print(dumps(sp_dict,indent=4))\n",
    "                  \n",
    "            #================ add narrative =======================\n",
    "            template = env.get_template(md_template[3])   \n",
    "            rendered = template.render(sp=sp_dict)\n",
    "    \n",
    "            display(HTML(rendered))\n",
    "            \n",
    "            parser = etree.XMLParser(remove_blank_text=True)\n",
    "            root = etree.fromstring(rendered, parser=parser)\n",
    "\n",
    "            div = (etree.tostring(root[1][0], encoding='unicode', method='html'))\n",
    "\n",
    "            narr = N.Narrative()\n",
    "            narr.status = 'generated'\n",
    "            narr.div = div\n",
    "                  \n",
    "            sp_dict['text'] = narr.as_json()\n",
    "      \n",
    "                  \n",
    "            # ================ save files as resource ======================\n",
    "           #save in ig_source folder\n",
    "            write_path = '' #comment out to save in ig\n",
    "       \n",
    "            path = Path.cwd() / write_path / 'resources' / f'searchparameter-{sp_dict[\"id\"]}.json'\n",
    "            if d.base not in skip_types:    #don't write test types  \n",
    "                path.write_text(dumps(sp_dict,indent=4))\n",
    "            sp_list.append(sp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate\n",
    "\n",
    "- validate sps if validate_flag variable is set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if validate_flag:\n",
    "    for i in sp_list:\n",
    "        print(f'Validating {i[\"id\"]}...........')\n",
    "        r = validate(i)\n",
    "        display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3>\\\n",
    "                     {r.json()[\"text\"][\"div\"]}'))\n",
    "else:\n",
    "    print(f'Validation Flag is set to {validate_flag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Quick Start pages using Jinja\n",
    " \n",
    "- spreadsheet for sp and combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out what Searchs are published in Quick Start\n",
    "\n",
    "-  all single SP with display = true ( SHALLs or SHOULDs)\n",
    "-  all SHALLs or SHOULDs combos\n",
    "- ignore all that begin with !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_type = dict(\n",
    "    token = '{system|}[code]',\n",
    "    id = '[id]',\n",
    "    reference = '{Type/}[id]',\n",
    "    string = '[string]',\n",
    "    uri = '[uri]',\n",
    "    date = '[date]',\n",
    "    )\n",
    "#  add sps not in search_profiles to search_profiles (combo_list)\n",
    "singles = {i.base for i in data}-{i for i in search_profiles.values()} \n",
    "singles_dict = {i.profile:i.base for i in data if i.base in singles}\n",
    "#pprint(singles_dict)\n",
    "#pprint(search_profiles)\n",
    "search_profiles.update(singles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitioner': 'Practitioner'}\n"
     ]
    }
   ],
   "source": [
    "pprint(search_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The actual rendering of a markdown Quick Start page\n",
    "\n",
    "#### new_content tag added to markdown if column is_new is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========http://hl7.org/fhir/us/core/StructureDefinition/us-core-practitioner Practitioner ==============\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "{% include quickstart-intro.md %}\n",
       "\n",
       "- The syntax used to describe the interactions is described [here](general-guidance.html#search-syntax).\n",
       "- See the [General Guidance] section for additional rules and expectations when a server requires status parameters.\n",
       "- See the [General Guidance] section for additional guidance on searching for multiple patients.\n",
       "\n",
       "#### Mandatory Search Parameters:\n",
       "\n",
       "The following search parameters and search parameter combinations SHALL be supported:\n",
       "\n",
       "1. **SHALL** support searching for a practitioner by a string match of any part of name using the **[`name`](SearchParameter-us-core-practitioner-name.html)** search parameter:\n",
       "\n",
       "    `GET [base]/Practitioner?name=[string]`\n",
       "\n",
       "    Example:\n",
       "    \n",
       "      1. GET [base]/Practitioner?name=Smith\n",
       "\n",
       "    *Implementation Notes:* Fetches a bundle of all Practitioner resources matching the name ([how to search by string])\n",
       "\n",
       "1. **SHALL** support searching a practitioner by an identifier such as an NPI using the **[`identifier`](SearchParameter-us-core-practitioner-identifier.html)** search parameter:\n",
       "\n",
       "    `GET [base]/Practitioner?identifier={system|}[code]`\n",
       "\n",
       "    Example:\n",
       "    \n",
       "      1. GET [base]/Practitioner?dentifier=http://hl7.org/fhir/sid/us-npi\\|97860456\n",
       "\n",
       "    *Implementation Notes:* Fetches a bundle containing any Practitioner resources matching the identifier ([how to search by token])\n",
       "\n",
       "\n",
       "#### Optional Search Parameters:\n",
       "\n",
       "The following search parameter combinations SHOULD be supported:\n",
       "\n",
       "1. {:.new-content}**SHOULD** support searching using the **[`_id`](SearchParameter-us-core-practitioner-id.html)** search parameter:\n",
       "\n",
       "     `GET [base]/Practitioner?_id={system|}[code]`\n",
       "\n",
       "    Example:\n",
       "    \n",
       "      1. GET [base]/Practitioner/practitioner-1\n",
       "      1. GET [base]/Practitioner?_id=practitioner-1\n",
       "\n",
       "     *Implementation Notes:* DOES THIS DO ANYTHING? ([how to search by token])\n",
       "\n",
       "\n",
       "\n",
       "{% include link-list.md %}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template = env.get_template(md_template[0])\n",
    "\n",
    "\n",
    "\n",
    "#print(r_type)   \n",
    "for profile,type in search_profiles.items():  # preprocess the for jinja templates\n",
    "\n",
    "    sp = [d for d in data if d.base == type]        \n",
    "    sp_combos = [d for d in combo_data if d.profile == profile]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(sp_combos[0].description)\n",
    "    mods= {}\n",
    "    rels = {}\n",
    "    for s in sp:\n",
    "            l1=s.shall_modifier.split(',') if s.shall_modifier else []\n",
    "            l2=s.should_modifier.split(',') if s.should_modifier else []\n",
    "            l3=s.shall_comparator.split(',') if s.shall_comparator else []\n",
    "            l4=s.should_comparator.split(',') if s.should_comparator else []\n",
    "            l5=s.shall_chain.split(',') if s.shall_chain else []\n",
    "            l6=s.should_chain.split(',') if s.should_chain else []\n",
    "            l7=s.shall_include.split(',') if s.shall_include else []\n",
    "            l8=s.should_include.split(',') if s.should_include else []\n",
    "            shall_multipleAnd= s.multipleAnd =='Y' and s.multipleAnd_conf =='SHALL'\n",
    "            should_multipleAnd=s.multipleAnd =='Y' and s.multipleAnd_conf =='SHOULD'\n",
    "            shall_multipleOr=s.multipleOr =='Y' and s.multipleOr_conf =='SHALL'\n",
    "            should_multipleOr=s.multipleOr =='Y' and s.multipleOr_conf =='SHOULD'\n",
    "            mods[s.code] = (\n",
    "                l1+l2,\n",
    "                l3+l4,\n",
    "                l1,\n",
    "                l2,\n",
    "                l3,\n",
    "                l4,\n",
    "                l5,\n",
    "                l6,\n",
    "                l7,\n",
    "                l8,\n",
    "                shall_multipleAnd,\n",
    "                should_multipleAnd,\n",
    "                shall_multipleOr,\n",
    "                should_multipleOr,\n",
    "                shall_multipleAnd or should_multipleAnd,\n",
    "                shall_multipleOr or should_multipleOr,\n",
    "                   )\n",
    "            #pprint(mods)\n",
    "            ''' 0,1 MODS AND COMPS 2,3 mods,\n",
    "            4.5 comps, 6,7 chains, 8,9 includes 10,11 multAnd, 12,13 multOr, 14 multAnds, 15 multOrs'''\n",
    "            rels[s.code] = s.rel_url.replace('_','')\n",
    "            #pprint(rels)\n",
    "\n",
    "    shalls = \"SHALL\" in [i.base_conf for i in sp if i.display] + [i.combo_conf for i in sp_combos if i.profile == profile]  # TODO need to search both singles and combos\n",
    "    shoulds = \"SHOULD\" in [i.base_conf for i in sp if i.display] + [i.combo_conf for i in sp_combos if i.profile == profile]\n",
    "\n",
    "    #print(f'''====== type ========\n",
    "    #{type}\n",
    "    #====== sp ========\n",
    "    #{sp}\n",
    "    #======= search_type =======\n",
    "    #{search_type}\n",
    "    #====== sp_combos ========\n",
    "    #{sp_combos}\n",
    "    #===== rels =========\n",
    "    #{rels}\n",
    "    #''')\n",
    "    \n",
    "\n",
    "    search_md = template.render(\n",
    "                    r_type=type,\n",
    "                    sp=sp,\n",
    "                    search_type=search_type,\n",
    "                    combos=sp_combos,\n",
    "                    shalls=shalls,\n",
    "                    shoulds=shoulds,\n",
    "                    mods = mods,\n",
    "                    rels = rels,\n",
    "                    )\n",
    "\n",
    "    print(f'========={profile} {type} ==============')\n",
    "    search_md = search_md.replace('\\n\\n\\n', '\\n\\n') #clean up line feeds\n",
    "    display(Markdown(search_md))\n",
    "    # save\n",
    "    if d.base not in skip_types:\n",
    "        write_path = '' #comment out to save in ig\n",
    "    \n",
    "        #write_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/input/\"\n",
    "        if \"quickstart\" in profile:\n",
    "            print(\"gos to includes folder  # need to figure how to write the include - where to put this information\")\n",
    "            path = Path.cwd() / write_path / '_includes' / f'{profile}.md'\n",
    "            path.write_text(search_md)\n",
    "        else:\n",
    "            path = Path.cwd() / write_path / 'intro-notes' / f'StructureDefinition-{profile.split(\"/\")[-1]}-notes.md'\n",
    "            path.write_text(search_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## DISABLED - USE Search-maker/SearchParameterListMaker.ipynb instead\n",
    " \n",
    " ### Create Markdown Text for SearchParameters Page\n",
    "\n",
    "- Using Jinja2 Template create markdown file for searchparameters page\n",
    "- Use spreadsheet as source"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for d in data:\n",
    "    if '!' in d.base:\n",
    "        print(d.base,True)\n",
    "\n",
    "# get id for each row in spreadsheet:\n",
    "r_list={d.base for d in data if '!' not in d.base and d.base not in skip_types}\n",
    "d_tup = []\n",
    "for d in data:\n",
    "    if d.base in r_list:\n",
    "        sp_id= [sp['id'] for sp in sp_list if d.base in sp['base'] and sp['code'] in [d.code,'id'] ]\n",
    "        d_tup.append((sp_id[0] if sp_id else None,d))\n",
    "\n",
    "template = env.get_template(md_template[1])   \n",
    "\n",
    "searchparameters_md = template.render(sp_list=d_tup,r_list=sorted(r_list))\n",
    "\n",
    "display(Markdown(searchparameters_md))\n",
    "# save in pages folder\n",
    "write_path = '' #comment out to save in ig\n",
    "path = Path.cwd() / write_path / 'pagecontent' / 'searchparameters.md'\n",
    "path.write_text(searchparameters_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
