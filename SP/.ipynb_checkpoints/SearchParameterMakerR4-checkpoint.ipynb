{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO :  change from sorting by resource type to profile\n",
    "\n",
    "## Create FHIR R4 SearchParameter Resource\n",
    "\n",
    "Create FHIR R4 SearchParameter Resource, Quick start text, and Searchparameter list using the python fhir client\n",
    "\n",
    "Source data is in excel file\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Python 3.7 or greater\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FHIRR4Client and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhirclient.r4models.fhirabstractbase import FHIRValidationError\n",
    "from fhirclient.r4models import searchparameter as SP\n",
    "from fhirclient.r4models import capabilitystatement as CS\n",
    "from fhirclient.r4models import bundle as B\n",
    "import fhirclient.r4models.identifier as I\n",
    "import fhirclient.r4models.coding as C\n",
    "import fhirclient.r4models.codeableconcept as CC\n",
    "import fhirclient.r4models.fhirdate as D\n",
    "import fhirclient.r4models.extension as X\n",
    "import fhirclient.r4models.contactdetail as CD\n",
    "from json import dumps, loads, load\n",
    "from requests import get, post, put\n",
    "import os\n",
    "from pathlib import Path\n",
    "from csv import reader as csvreader\n",
    "from IPython.display import display as Display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "from pandas import *\n",
    "from datetime import datetime\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "import R4sp_summary_list as sp_map\n",
    "from stringcase import snakecase, titlecase, pascalcase\n",
    "from itertools import zip_longest\n",
    "from openpyxl import load_workbook\n",
    "import R4sp_summary_list as sp_map\n",
    "from itertools import zip_longest\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Assign Global Variables\n",
    "\n",
    "\n",
    "Here is where we assign all the global variables for this example such as the local paths for file input and output\n",
    "\n",
    "##### Need to update:\n",
    "- base_id\n",
    "- paths\n",
    "- canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** Need to update *************************************************\n",
    "fhir_base_url = 'http://hl7.org/fhir/'\n",
    "base_id = \"US-Core\"\n",
    "canon_base = \"http://hl7.org/fhir/us/core/\"\n",
    "ig_folder = 'US-Core'\n",
    "publisher = 'HL7 International - Structured Documents Work Group'\n",
    "publisher_endpoint = dict(\n",
    "                        system = 'url',\n",
    "                        value = 'http://www.hl7.org/Special/committees/structure/index.cfm'\n",
    "                        ) \n",
    "ig_source_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/source/\"\n",
    "#ig_source_path = \"/Users/ehaas/Documents/FHIR/US-Core-R4/source/\"\n",
    "ig_source_path = ''\n",
    "\n",
    "\n",
    "spdef_json = 'C:/Users/Eric/Documents/HL7/FHIR/BUILD_EDIT_FILES/R4_Definitions/search-parameters.json'\n",
    "#spdef_json ='/Users/ehaas/Downloads/definitionsR4.json/search-parameters.json'\n",
    "\n",
    "skip_types = ['Questionnaire']\n",
    "#***********************************************************************************\n",
    "\n",
    "env = Environment(\n",
    "    loader=FileSystemLoader(searchpath = ''),\n",
    "    autoescape=select_autoescape(['html','xml','xhtml','j2','md'])\n",
    "    )\n",
    "\n",
    "md_template = ['quick_start.j2', 'sp_list_page.j2', 'cs_search_documentation.j2','sp_narrative.j2']\n",
    "\n",
    "\n",
    "fhir_term_server = 'http://test.fhir.org/r3'\n",
    "\n",
    "# profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    "\n",
    "\n",
    "\n",
    "none_list = ['', ' ', 'none', 'n/a', 'N/A', 'N', 'False', 'FALSE']\n",
    "sep_list = (',', ';', ' ', ', ', '; ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** validate Resource as Dict ********************************\n",
    "\n",
    "def validate(r):\n",
    "\n",
    "    fhir_test_server = 'http://test.fhir.org/r4'\n",
    "\n",
    "    headers = {\n",
    "    'Accept':'application/fhir+json',\n",
    "    'Content-Type':'application/fhir+json'\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "    }\n",
    "    \n",
    "    r = post(f'{fhir_test_server}/{r[\"resourceType\"]}/$validate', params = params, headers = headers, data = dumps(r))\n",
    "    # return r.status_code\n",
    "    # view  output\n",
    "    # return (r.json()[\"text\"][\"div\"])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Search Parameter input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_path = '/Users/ehaas/Documents/FHIR/pyfhir/test/'\n",
    "in_path =''\n",
    "\n",
    "in_file =\"uscore-server\"\n",
    "\n",
    "xls = ExcelFile(f'{in_path}{in_file}.xlsx')\n",
    "df = read_excel(xls,'sps',na_filter = False)\n",
    "df_combos = read_excel(xls,'sp_combos',na_filter = False)\n",
    "\n",
    "df_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [i for i in df.itertuples(index=True)]\n",
    "r_type =  {d.base for d in data if '!' not in d.base}\n",
    "combo_data = [i for i in df_combos.itertuples(index=True)]\n",
    "search_profiles = {i.profile:i.base for i in combo_data if '!' not in i.base }\n",
    "\n",
    "for d in data:\n",
    "    print(f'Resource = {d.base}, Search Parameter = {d.code}, Exists = {d.exists}')\n",
    "for c in combo_data:\n",
    "    print(f'Resource = {c.base}, Combo Search Parameter = {c.combo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update core SP with additional capabiliities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Get definitions bundle and convert to python object for ease of notation\n",
    "- use sp_map to map to Type + parameter\n",
    "- If need to update SP Extract the SP based on the excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load SP Mapping dictionary\n",
    "\n",
    "output shows a single SP entry for a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(spdef_json)\n",
    "b = B.Bundle(loads(p.read_text()), strict = False)\n",
    "sp = (i.resource for i in b.entry if i.resource.url == 'http://hl7.org/fhir/SearchParameter/Resource-id')\n",
    "sp_for_id = next(sp)\n",
    "print(dumps(sp_for_id.as_json(), indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create updated SPs\n",
    "sp optional 'modifier' elements are listed as comma separated list of shalls and shoulds for each:\n",
    "- multipleOr\n",
    "- multipleOr_conf\n",
    "- multipleAnd\n",
    "- multipleAnd_conf\n",
    "- shall_modifier\n",
    "- should_modifier\n",
    "- shall_comparator\n",
    "- should_comparator\n",
    "- shall_chain\n",
    "\n",
    "if not spedified then conformance is MAY \n",
    "\n",
    "*note that it starts out using the FHIRClient models but the switches to a dict structure to add the FHIR primitive type extensions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_expectation(conf=None):\n",
    "    if not conf:\n",
    "        conf = \"MAY\"\n",
    " \n",
    "    x = X.Extension(dict(\n",
    "    url = f'http://hl7.org/fhir/StructureDefinition/capabilitystatement-expectation',\n",
    "    valueCode = conf\n",
    "    ))\n",
    "    x_dict = dict(\n",
    "    extension = [x.as_json()]\n",
    "    ) \n",
    "    return x_dict\n",
    "\n",
    "def find_base_sp(d):\n",
    "    if '!' not in d.base and d.update =='Y':\n",
    "        #print(d.base, d.code)\n",
    "        if d.code == '_id':\n",
    "            sp = SP.SearchParameter(sp_for_id.as_json())\n",
    "        else:\n",
    "            sp = next(i.resource for i in b.entry if i.resource.code == d.code and d.base in i.resource.base)       \n",
    "            sp = SP.SearchParameter(sp.as_json())\n",
    "        return sp\n",
    "\n",
    "\n",
    "sp_list=[]\n",
    "for d in data:\n",
    "        print(f'========={d.base},{d.code}==============')\n",
    "        sp = find_base_sp(d)\n",
    "        #print(type(sp))\n",
    "        if sp:\n",
    "            #print(sp.url)\n",
    "            # change id and url, publisher, and contact, draft etc\n",
    "            sp.id = f'{base_id.lower()}-{d.base.lower()}-{d.code.replace(\"_\",\"\")}'  \n",
    "            sp.extension = []\n",
    "            sp.derivedFrom =sp.url\n",
    "            sp.url = f'{canon_base}SearchParameter/{sp.id}'\n",
    "            sp.publisher = publisher\n",
    "            sp.contact = [CD.ContactDetail( {\"telecom\" : [ publisher_endpoint ] })]\n",
    "            sp.date = D.FHIRDate(f'{datetime.utcnow().isoformat()}Z')\n",
    "            sp.name = pascalcase(sp.id.replace('-','_'))\n",
    "            sp.name = sp.name.replace('UsCore','USCore')\n",
    "            sp.status = 'active'\n",
    "\n",
    "            sp.base = [d.base]\n",
    "            \n",
    "            try:\n",
    "                sp.expression = [i for i in sp.expression.split('|') if i.startswith(f'{d.base}.')][0]\n",
    "            except IndexError:\n",
    "                try:\n",
    "                    sp.expression = [i for i in sp.expression.split(' | ') if i.startswith(f'{d.base}.')][0]\n",
    "                except IndexError:\n",
    "                    sp.expression = f'{d.base}.id'\n",
    "            try:\n",
    "                sp.xpath = [i for i in sp.xpath.split('|') if i.startswith(f'f:{d.base}/')][0]\n",
    "                sp.xpath = sp.xpath.strip()\n",
    "            except IndexError:\n",
    "                try:\n",
    "                    sp.xpath = [i for i in sp.xpath.split(' | ') if i.startswith(f'f:{d.base}/')][0]\n",
    "                    sp.xpath = sp.xpath.strip()\n",
    "                except IndexError:\n",
    "                    sp.xpath = f'{d.base}.id'\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            try:   \n",
    "                sp.description = [i for i in sp.description.split('\\r\\n* ') if i.startswith(f'[{d.base}]')][0]\n",
    "                sp.description = sp.description.split(': ')[1:]\n",
    "                sp.description = ''.join(sp.description)\n",
    "            except IndexError:   \n",
    "                print(sp.expression)\n",
    "            sp.expression = sp.expression.strip()\n",
    "            sp.description = sp.description.strip() \n",
    "\n",
    "  \n",
    "            #convert to dict since model can't handle primitive extensions\n",
    "            sp_dict = sp.as_json()\n",
    "\n",
    "            sp_dict['multipleOr'] = False if d.multipleOr in none_list else True\n",
    "            sp_dict['_multipleOr'] = sp_expectation(d.multipleOr_conf)\n",
    "            \n",
    "            sp_dict['multipleAnd'] = False if d.multipleAnd in none_list else True\n",
    "            sp_dict['_multipleAnd'] = sp_expectation(d.multipleAnd_conf)\n",
    "\n",
    "            try:\n",
    "                sp_dict['_modifier'] = []\n",
    "                for m in sp_dict['modifier']: # list all modifiers in sp and assign an expectation.\n",
    "                    if d.shall_modifier not in none_list and m in d.shall_modifier.split(','):\n",
    "                       sp_dict['_modifier'].append(sp_expectation('SHALL'))\n",
    "                    elif  d.should_modifier not in none_list and m in d.should_modifier.split(','):\n",
    "                        sp_dict['_modifier'].append(sp_expectation('SHOULD'))               \n",
    "                    else:\n",
    "                        sp_dict['_modifier'].append(sp_expectation('MAY'))\n",
    "            except KeyError:\n",
    "                del(sp_dict['_modifier'])\n",
    "\n",
    "            try:\n",
    "                sp_dict['_comparator'] = []\n",
    "                for m in sp_dict['comparator']: # list all comparators in sp and assign an expectation.\n",
    "                   if d.shall_comparator not in none_list and m in d.shall_comparator.split(','):\n",
    "                       sp_dict['_comparator'].append(sp_expectation('SHALL'))\n",
    "                   elif  d.should_comparator not in none_list and m in d.should_comparator.split(','):\n",
    "                        sp_dict['_comparator'].append(sp_expectation('SHOULD'))               \n",
    "                   else:\n",
    "                        sp_dict['_comparator'].append(sp_expectation('MAY'))\n",
    "            except KeyError:\n",
    "                del(sp_dict['_comparator'])\n",
    "\n",
    "            if d.shall_chain not in none_list:\n",
    "               sp_dict['chain'] = d.shall_chain.split(',')\n",
    "               sp_dict['_chain'] = [sp_expectation('SHALL') for c in d.shall_chain.split(',')]\n",
    "\n",
    "            if d.should_chain not in none_list:\n",
    "               sp_dict['chain'] = d.should_chain.split(',')\n",
    "               sp_dict['_chain'] = [sp_expectation('SHALL') for c in d.should_chain.split(',')]\n",
    "\n",
    "            print(f'======================= SP = {sp_dict[\"id\"]} =====================')\n",
    "            #print(dumps(sp_dict,indent=4))\n",
    "                  \n",
    "            #================ add narrative =======================\n",
    "            template = env.get_template(md_template[3])   \n",
    "            sp_text = template.render(sp=sp_dict)\n",
    "            #print(sp_text)     \n",
    "            display(HTML(sp_text))\n",
    "                  \n",
    "            sp_dict['text'] = {}\n",
    "            sp_dict['text']['status'] = \"generated\"\n",
    "            sp_dict['text']['div'] = sp_text      \n",
    "                  \n",
    "            # ================ save files as resource ======================\n",
    "           #save in ig_source folder\n",
    "            path = Path.cwd() / ig_source_path / 'resources' / f'searchparameter-{sp_dict[\"id\"]}.json'\n",
    "            if d.base not in skip_types:    #don't write test types  \n",
    "                path.write_text(dumps(sp_dict,indent=4))\n",
    "            sp_list.append(sp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sp_list:\n",
    "    print(f'Validating {i[\"id\"]}...........')\n",
    "    r = validate(i)\n",
    "    display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Quick Start pages using Jinja\n",
    " \n",
    "- spreadsheet for sp and combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_type = dict(\n",
    "    token = '{[system]}|[code]',\n",
    "    id = '[id]',\n",
    "    reference = '[reference]',\n",
    "    string = '[string]',\n",
    "    uri = '[uri]',\n",
    "    date = '[date]',\n",
    "    )\n",
    "#  add sps not in search_profiles to search_profiles (combo_list)\n",
    "singles = {i.base for i in data if '!' not in i.base}-{i for i in search_profiles.values()} \n",
    "singles_dict = {i.profile:i.base for i in data if i.base in singles}\n",
    "#pprint(singles_dict)\n",
    "#pprint(search_profiles)\n",
    "search_profiles.update(singles_dict)\n",
    "#pprint(search_profiles)\n",
    "template = env.get_template(md_template[0])\n",
    "\n",
    "\n",
    "\n",
    "#print(r_type)   \n",
    "for profile,type in search_profiles.items():  # preprocess the for jinja templates\n",
    "\n",
    "    sp = [d for d in data if d.base == type]\n",
    "    sp_combos = [d for d in combo_data if d.profile == profile]\n",
    "    #print(sp_combos[0].base)\n",
    "    mods= {}\n",
    "    rels = {}\n",
    "    for s in sp:\n",
    "            l1=s.shall_modifier.split(',') if s.shall_modifier else []\n",
    "            l2=s.should_modifier.split(',') if s.should_modifier else []\n",
    "            l3=s.shall_comparator.split(',') if s.shall_comparator else []\n",
    "            l4=s.should_comparator.split(',') if s.should_comparator else []\n",
    "            l5=s.shall_chain.split(',') if s.shall_chain else []\n",
    "            l6=s.should_chain.split(',') if s.should_chain else []\n",
    "            l7=s.shall_include.split(',') if s.shall_include else []\n",
    "            l8=s.should_include.split(',') if s.should_include else []\n",
    "            mods[s.code] = (l1+l2,l3+l4,l1,l2,l3,l4,l5,l6,l7,l8,) # 0,1 MODS AND COMPS 2,3 mods, 4.5 comps, 6,7 chains, 8,9 includes\n",
    "            rels[s.code] = s.rel_url\n",
    "    \n",
    "    #print(mods, rels)\n",
    "    \n",
    "\n",
    "    shalls = \"SHALL\" in [i.base_conf for i in sp if i.display] + [i.combo_conf for i in sp_combos if i.profile == profile]  # TODO need to search both singles and combos\n",
    "    shoulds = \"SHOULD\" in [i.base_conf for i in sp if i.display] + [i.combo_conf for i in sp_combos if i.profile == profile]\n",
    "    #pprint(rels)\n",
    "  \n",
    "    search_md = template.render(\n",
    "                    r_type=type,\n",
    "                    sp=sp,\n",
    "                    search_type=search_type,\n",
    "                    combos=sp_combos,\n",
    "                    shalls=shalls,\n",
    "                    shoulds=shoulds,\n",
    "                    mods = mods,\n",
    "                    rels = rels,\n",
    "                    )\n",
    "\n",
    "    print(f'========={profile} {type} ==============')\n",
    "    display(Markdown(search_md))\n",
    "    # save\n",
    "    if d.base not in skip_types:\n",
    "        path = Path.cwd() / ig_source_path / 'pages' / '_includes' / f'{profile.split(\"/\")[-1]}-search.md'\n",
    "        path.write_text(search_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Markdown Text for SearchParameters Page\n",
    "\n",
    "- Using Jinja2 Template create markdown file for searchparameters page\n",
    "- Use spreadsheet as source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    if '!' in d.base:\n",
    "        print(d.base,True)\n",
    "\n",
    "# get id for each row in spreadsheet:\n",
    "r_list={ d.base for d in data if '!' not in d.base and d.base not in skip_types}\n",
    "d_tup = []\n",
    "for d in data:\n",
    "    if d.base in r_list:\n",
    "        sp_id= [sp['id'] for sp in sp_list if d.base in sp['base'] and sp['code'] in [d.code,'id'] ]\n",
    "        d_tup.append((sp_id[0] if sp_id else None,d))\n",
    "\n",
    "template = env.get_template(md_template[1])   \n",
    "\n",
    "searchparameters_md = template.render(sp_list=d_tup,r_list=r_list)\n",
    "\n",
    "display(Markdown(searchparameters_md))\n",
    "# save in pages folder\n",
    "ig_source_path = ''  # temp folder\n",
    "path = Path.cwd() / ig_source_path / 'pages' / 'searchparameters.md'\n",
    "path.write_text(searchparameters_md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
