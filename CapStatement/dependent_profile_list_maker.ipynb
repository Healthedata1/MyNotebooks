{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all must support dependent profiles in StructureDefinitions\n",
    "\n",
    "- see FHIR-39723\n",
    "- for hard coded path search all SD (in YAML) for:\n",
    "  -  all reference with must support = true profiles\n",
    "  -  all reference with must support = true and add't USCDI profiles when add add'l USCDI equal True\n",
    "- list of other profile that need to be supported\n",
    "- incorporate into narrative generator...\n",
    "- do same for uscdi requirements with global parameter \n",
    "- todo think about canonical too and inherited references from base. (such as Media) use snapshot instead?\n",
    "  - check if inherited reference if emopty ( e.g. Media )\n",
    "- associated url with title to publish  (see narrative generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from json import load, dumps\n",
    "from yaml import load as y_load, dump as y_dump, FullLoader\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "yml_path = Path('/Users/ehaas/Documents/FHIR/US-Core/input/resources-yaml')\n",
    "snapshot_path =  Path('/Users/ehaas/Documents/FHIR/US-Core/output')  # use this\n",
    "\n",
    "my_path = snapshot_path\n",
    "ig_base_url = 'http://hl7.org/fhir/us/core/'  # US Core don't forget the trailing /\n",
    "fhir_base = 'http://hl7.org/fhir/' # canonical url for FHIR don't forget the trailing /\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Profile Canonicals to Relative References "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical_to_path(canonical):\n",
    "    if canonical.startswith(ig_base_url):\n",
    "        relative_path_parts = canonical.split(ig_base_url)[-1].split('/')\n",
    "        print(relative_path_parts)\n",
    "        return f\"{relative_path_parts[0]}-{relative_path_parts[1]}.html\"\n",
    "    else:\n",
    "        return canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical = 'http://hl7.org/fhir/StructureDefinition/CapabilityStatement'\n",
    "print(canonical_to_path(canonical))  # test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_dict():\n",
    "    type_map={}\n",
    "    title_map={}\n",
    "    derived_map={}\n",
    "    mydict = {}\n",
    "    excludelist = []\n",
    "    # print(f'addl_uscdi={addl_uscdi}')\n",
    "    whitelist = []\n",
    "\n",
    "    count = 0\n",
    "    cant_match_path = []\n",
    "\n",
    "    for i in sorted(my_path.glob('Struct*.json')):\n",
    "        my_urls = set() # MS only set\n",
    "        my_uscdi_urls = set() # MS + USCDI set\n",
    "\n",
    "        obj = y_load(i.read_text(),Loader=FullLoader) #dict\n",
    "        if obj['id'] in excludelist or obj['type'] == 'Extension':\n",
    "            continue\n",
    "        type_map[obj['url']] = obj['type']\n",
    "        title_map[obj['url']] = obj['title']\n",
    "        derived_map[obj['url']] = obj['baseDefinition']\n",
    "        # print(enum,i,)\n",
    "        # print(obj['url'])\n",
    "        #find references type elements in diff\n",
    "        for element in obj['differential']['element']:\n",
    "            # print(element['id'])\n",
    "            # print()\n",
    "        \n",
    "            try:\n",
    "                targetProfile = (type for type in element['type'] if type['code'] == 'Reference').__next__()['targetProfile']\n",
    "            except KeyError:\n",
    "                # find snapshot_element\n",
    "                try:\n",
    "                    snapshot_element =  (snapshot_element for snapshot_element in obj['snapshot']['element'] if snapshot_element['id'] == element['id']).__next__()\n",
    "                    # check if snapshot_element has a type reference\n",
    "                except StopIteration:\n",
    "                    # print('id mismatch')\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        snapshot_reference = (type for type in snapshot_element['type'] if type['code'] == 'Reference').__next__()['targetProfile']\n",
    "                        # print(f\"++++++++++++++++snapshot_reference={snapshot_reference}+++++++++++++++++++++\")\n",
    "                        try:\n",
    "                            if element['mustSupport']: # only Must Supports / no add;l uscdi elements\n",
    "                                my_urls.update(snapshot_reference) #add list to set\n",
    "                        except KeyError: # Add;l USCDI\n",
    "                            my_uscdi_urls.update(snapshot_reference) #add list to set\n",
    "\n",
    "                    except KeyError:\n",
    "                        # print('not a type = reference')\n",
    "                        pass\n",
    "                    except StopIteration:\n",
    "                        # print('not a type = reference')\n",
    "                        pass\n",
    "            except StopIteration:\n",
    "                # print('no reference')\n",
    "                pass\n",
    "            else:\n",
    "                ms_ext = None\n",
    "                try:\n",
    "                    ms_ext = (type for type in element['type'] if type['code'] == 'Reference').__next__()['_targetProfile']\n",
    "                except KeyError:\n",
    "                    # print('no  _targetProfile')\n",
    "                    pass\n",
    "                except StopIteration:\n",
    "                    # print('stopIteration')\n",
    "                    pass\n",
    "\n",
    "                # print(targetProfile, ms_ext)\n",
    "                \n",
    "                # print(element['id'])\n",
    "                # print(dict(zip(targetProfile,ms_ext)))\n",
    "                # print()\n",
    "                try:\n",
    "                    zipped = dict(zip(targetProfile,ms_ext))\n",
    "                    ms_targetProfile = [k for k,v in zipped.items() if v[\"extension\"][0]['valueBoolean']]\n",
    "                    # print(f\"{element['id']} = {ms_targetProfile}\\n\")\n",
    "                    try:\n",
    "                        if element['mustSupport']: # only Must Supports / no add;l uscdi elements\n",
    "                            my_urls.update(ms_targetProfile) #add list to set\n",
    "                    except KeyError: # Must Supports + Add;l USCDI\n",
    "                        my_uscdi_urls.update(ms_targetProfile) #add list to set\n",
    "                except TypeError:\n",
    "                    # print(f\"{element['id']} = {targetProfile}\\n\")\n",
    "                    try:\n",
    "                        if element['mustSupport']: # only Must Supports / no add;l uscdi elements\n",
    "                            my_urls.update(targetProfile) #add list to set\n",
    "                    except KeyError: # Must Supports + Add;l USCDI\n",
    "                        my_uscdi_urls.update(targetProfile) #add list to set             \n",
    "        # print(f'my_uscdi_urls = {my_uscdi_urls}\\n')\n",
    "        # if addl_uscdi:\n",
    "        #     mydict[obj['url']] = list(my_uscdi_urls)\n",
    "        # else:\n",
    "        #     mydict[obj['url']] = list(my_urls)\n",
    "\n",
    "        mydict[obj['url']] = [(i,False) for i in list(my_urls)] + [(i,True) for i in list(my_uscdi_urls)]\n",
    "\n",
    "    ### update profiles derived from other US Core profiles\n",
    "\n",
    "    #- iterate through and combine lists of profiles from parent profiles.   \n",
    "    for k,v in derived_map.items():\n",
    "        if v in mydict.keys():\n",
    "            # print(k,v,mydict[k],mydict[v])\n",
    "            mydict[k] = mydict[k] + mydict[v]\n",
    "    pprint(f\"mydict={mydict}\")\n",
    "    # print('return mydict, type_map, title_map')\n",
    "    pprint(f'title_map={title_map}')\n",
    "    return mydict, type_map, title_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map in the the links to US Core IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references_summary():\n",
    "    \n",
    "    mydict,type_map,title_map = get_my_dict()\n",
    "    keys = list(mydict.keys())\n",
    "    r_types_keys = [type_map[k] for k in keys]\n",
    "    # uscore_profile_links\n",
    "    uscore_profile_links = [f'<a href=\"{canonical_to_path(k)}\">{title_map[k]}</a>' for k in keys]\n",
    "    # resource_links\n",
    "    resource_links = [f'<a href=\"#{k.lower()}\">{k}</a>' for k in r_types_keys]\n",
    "    # target profile links\n",
    "    values = list(mydict.values())\n",
    "    t_profile_links = []\n",
    "    t_types_links = []\n",
    "    for v in values:\n",
    "        p_links=[]\n",
    "        r_links=[]\n",
    "        for target, is_uscdi in v:\n",
    "            try:\n",
    "                p_links.append(f'<a href=\"{canonical_to_path(target)}\">{title_map[target]}</a>{ \"(ADDITIONAL USCDI)\" if is_uscdi else \"\"}')\n",
    "                r_links.append(f'<a href=\"#{type_map[target].lower()}\">{type_map[target]}</a>')\n",
    "            except KeyError:\n",
    "                if target == \"http://hl7.org/fhir/StructureDefinition/Resource\":\n",
    "                    p_links.append(f'<a href=\"#\">Any Resource</a>{ \"(ADDITIONAL USCDI)\" if is_uscdi else \"\"}')\n",
    "                    r_links.append(f'<a href=\"#\">Any Resource</a>')\n",
    "                else:\n",
    "                    p_links.append(f'<a href=\"#{target.split(\"/\")[-1].lower()}\">{target.split(\"/\")[-1]}</a>{ \"(ADDITIONAL USCDI)\" if is_uscdi else \"\"}')\n",
    "                    r_links.append(f'<a href=\"#{target.split(\"/\")[-1].lower()}\">{target.split(\"/\")[-1]}</a>')\n",
    "\n",
    "        t_profile_links.append('<br />'.join(p_links))\n",
    "        t_types_links.append('<br />'.join(r_links))\n",
    "  \n",
    "\n",
    "    #t_types_values\n",
    "    references_summary = {'US Core Profile': uscore_profile_links, 'Resource Type':resource_links, 'Target US Core Profile or FHIR Resource': t_profile_links,  'Target Resource Type':t_types_links}\n",
    "    # for i, v in enumerate(references_summary[\"US Core Profile\"]):\n",
    "    #     for r in references_summary:\n",
    "    #         print(references_summary[r][i])\n",
    "    #     print(\"---\")\n",
    "    # print( f\"return references_summary = {y_dump(references_summary)}\")\n",
    "    return references_summary\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a table in jinja with links etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "    in_path = ''\n",
    "    in_file = 'test.j2'\n",
    "    def markdown(text, *args, **kwargs):\n",
    "        return commonmark(text, *args, **kwargs)\n",
    "\n",
    "    env = Environment(\n",
    "        loader=FileSystemLoader(searchpath = in_path),\n",
    "        autoescape=select_autoescape(['html','xml','xhtml','j2','md'],),\n",
    "        trim_blocks = True,\n",
    "        lstrip_blocks = True,\n",
    "        )\n",
    "    env.filters['markdown'] = markdown\n",
    "    template = env.get_template(in_file)\n",
    "\n",
    "    references_summary = get_references_summary()\n",
    "    # print(f\"summary of references =  {[(r,references_summary['Target US Core Profile or FHIR Resource'][i]) for i,r in enumerate(references_summary['US Core Profile']) if references_summary['Target US Core Profile or FHIR Resource'][i] != '']}\")\n",
    "    rendered = template.render(references_summary=references_summary)\n",
    "    return (rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # from IPython.display import display, HTML\n",
    "    print(\"main\")\n",
    "    # global addl_uscdi\n",
    "    # addl_uscdi = True\n",
    "    my_table = main()\n",
    "    display(HTML(my_table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18672f2fb81dcbb023a0ac48a86c775a19488782369d96ffbd3382a22fd285cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
