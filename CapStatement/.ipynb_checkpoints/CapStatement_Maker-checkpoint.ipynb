{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FHIR STU3 CapStatement Resource\n",
    "\n",
    "### Outline:\n",
    "\n",
    "- Source excel with requirements\n",
    "- pandas to convert in python Ordered Dict\n",
    "- build json\n",
    "- generate narrative using Jinja2 templates\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Python 3.6 or greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FHIRClient and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhirclient.models import searchparameter as SP\n",
    "from fhirclient.models import capabilitystatement as CS\n",
    "from fhirclient.models import bundle as B\n",
    "from fhirclient.models import narrative as N\n",
    "import fhirclient.models.identifier as I\n",
    "import fhirclient.models.coding as C\n",
    "import fhirclient.models.codeableconcept as CC\n",
    "import fhirclient.models.fhirdate as D\n",
    "import fhirclient.models.extension as X\n",
    "import fhirclient.models.contactdetail as CD\n",
    "import fhirclient.models.fhirreference as FR\n",
    "from json import dumps, loads, load\n",
    "from requests import get, post, put\n",
    "import os\n",
    "from pathlib import Path\n",
    "from csv import reader as csvreader\n",
    "from pprint import pprint\n",
    "from stringcase import snakecase, titlecase\n",
    "from collections import namedtuple\n",
    "from pandas import *\n",
    "from datetime import date\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "from commonmark import commonmark\n",
    "from IPython.display import display, HTML\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect ElementProperties as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('extension',\n",
       "  'extension',\n",
       "  fhirclient.models.extension.Extension,\n",
       "  True,\n",
       "  None,\n",
       "  False),\n",
       " ('id', 'id', str, False, None, False),\n",
       " ('modifierExtension',\n",
       "  'modifierExtension',\n",
       "  fhirclient.models.extension.Extension,\n",
       "  True,\n",
       "  None,\n",
       "  False),\n",
       " ('compartment', 'compartment', str, True, None, False),\n",
       " ('documentation', 'documentation', str, False, None, False),\n",
       " ('interaction',\n",
       "  'interaction',\n",
       "  fhirclient.models.capabilitystatement.CapabilityStatementRestInteraction,\n",
       "  True,\n",
       "  None,\n",
       "  False),\n",
       " ('mode', 'mode', str, False, None, True),\n",
       " ('operation',\n",
       "  'operation',\n",
       "  fhirclient.models.capabilitystatement.CapabilityStatementRestOperation,\n",
       "  True,\n",
       "  None,\n",
       "  False),\n",
       " ('resource',\n",
       "  'resource',\n",
       "  fhirclient.models.capabilitystatement.CapabilityStatementRestResource,\n",
       "  True,\n",
       "  None,\n",
       "  False),\n",
       " ('searchParam',\n",
       "  'searchParam',\n",
       "  fhirclient.models.capabilitystatement.CapabilityStatementRestResourceSearchParam,\n",
       "  True,\n",
       "  None,\n",
       "  False),\n",
       " ('security',\n",
       "  'security',\n",
       "  fhirclient.models.capabilitystatement.CapabilityStatementRestSecurity,\n",
       "  False,\n",
       "  None,\n",
       "  False)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CS.CapabilityStatementRest().elementProperties()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Assign Global Variables\n",
    "\n",
    "\n",
    "Here is where we assign all the global variables for this example such as the canonical base and project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhir_term_server = 'http://test.fhir.org/r3'\n",
    "fhir_test_server = 'http://test.fhir.org/r3'\n",
    "\n",
    "headers = {\n",
    "'Accept':'application/fhir+json',\n",
    "'Content-Type':'application/fhir+json'\n",
    "}\n",
    "\n",
    "fhir_base_url = 'http://hl7.org/fhir/'\n",
    "\n",
    "#canon = \"http://fhir.org/guides/argonaut-questionnaire/\"\n",
    "#canon = 'http://fhir.org/guides/argonaut-clinicalnotes/'\n",
    "canon = 'http://hl7.org/fhir/us/davinci-deqm/STU3/'\n",
    "\n",
    "#pre = \"Argonaut\"\n",
    "pre = 'DaVinci DEQM'\n",
    "\n",
    "#publisher = 'The Argonaut Project'\n",
    "publisher = 'The DaVinci Project'\n",
    "\n",
    "\n",
    "'''publisher_endpoint = dict(\n",
    "                        system = 'url',\n",
    "                        value = 'https://github.com/argonautproject/questionnaire/issues'\n",
    "                        )\n",
    "'''\n",
    "\n",
    "publisher_endpoint = dict(\n",
    "                        system = 'url',\n",
    "                        value = 'http://www.hl7.org/Special/committees/cqi/index.cfm'\n",
    "                        )\n",
    "\n",
    "\n",
    "f_jurisdiction =  CC.CodeableConcept({\n",
    "      \"coding\" : [\n",
    "        {\n",
    "          \"system\" : \"urn:iso:std:iso:3166\",\n",
    "          \"code\" : \"US\"\n",
    "        }\n",
    "      ]\n",
    "    })\n",
    "\n",
    "conf_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-expectation'\n",
    "combo_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-search-parameter-combination'\n",
    "\n",
    "none_list = ['', ' ', 'none', 'n/a', 'N/A', 'N', 'False']\n",
    "\n",
    "sep_list = (',', ';', ' ', ', ', '; ')\n",
    "\n",
    "f_now = D.FHIRDate(str(date.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conformance Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf(conf='MAY'):\n",
    "    return [X.Extension(dict(\n",
    "        url = conf_url,\n",
    "        valueCode = conf\n",
    "        ))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** validate Resource ********************************\n",
    "\n",
    "def validate(r):\n",
    "    fhir_test_server = 'http://fhirtest.uhn.ca/baseDstu3'\n",
    "    #fhir_test_server = 'http://test.fhir.org/r3'\n",
    "\n",
    "    headers = {\n",
    "    'Accept':'application/fhir+json',\n",
    "    'Content-Type':'application/fhir+json'\n",
    "    }\n",
    "\n",
    "    # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    " \n",
    "    params = dict(\n",
    "      # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    "        )\n",
    "    \n",
    "    #   r = requests.post('https://httpbin.org/post', data = {'key':'value'})\n",
    "    r = post(f'{fhir_test_server}/Questionnaire/$validate', params = params, headers = headers, data = dumps(r.as_json()))\n",
    "    # return r.status_code\n",
    "    # view  output\n",
    "    # return (r.json()[\"text\"][\"div\"])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def write_file(name, data): # write file\n",
    "    #out_path = ''\n",
    "    #out_path = '//ERICS-AIR-2/ehaas/Documents/FHIR/Argo-Questionnaire/source/resources/'\n",
    "    out_path = '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/source/resources/'\n",
    "    with open(f'{Path(out_path)}/{name}.json', 'w') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cap Statement input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first the meta sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/source/capstat_spreadsheets/DEQM_Capability_Statement_Consumer_Client.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e99911300895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mxls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{in_path}{in_file}.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'meta'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mna_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/source/capstat_spreadsheets/DEQM_Capability_Statement_Consumer_Client.xlsx'"
     ]
    }
   ],
   "source": [
    "#in_path = Path('/Users/ehaas/Documents/FHIR/pyfhir/test/')\n",
    "in_path ='/ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/source/capstat_spreadsheets/'\n",
    "#out_path = '/Users/ehaas/Documents/FHIR/pyfhir/test/'\n",
    "out_path=''\n",
    "#out_path = Path(\"C:/Users/Eric/Documents/Jan_2019_FHIR_Experience\")\n",
    "\n",
    "# in_file = 'AssBank'\n",
    "# in_file = 'AnsBank'\n",
    "# in_file = 'EHRProvider'\n",
    "#in_file = 'AdaptService'\n",
    "#in_file = 'Argonaut_Capability_Statement_Clinical_Notes'\n",
    "#in_file = 'Argonaut_Capability_Statement_CLIENT_Clinical_Notes'\n",
    "\n",
    "in_file = \"DEQM_Capability_Statement_Consumer_Client\"\n",
    "#in_file = \"DEQM_Capability_Statement_Reporter_Client\"\n",
    "#in_file = \"DEQM_Capability_Statement_Consumer_Server\"\n",
    "#in_file = \"DEQM_Capability_Statement_Producer_Client\"\n",
    "#in_file = \"DEQM_Capability_Statement_Producer_Server\"\n",
    "#in_file = \"DEQM_Capability_Statement_Receiver_Server\"\n",
    "\n",
    "\n",
    "xls = ExcelFile(f'{in_path}{in_file}.xlsx')\n",
    "df = read_excel(xls,'meta',na_filter = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NamedTuple from df to use dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(df.Element, df.Value))\n",
    "meta = namedtuple(\"Meta\", d.keys())(*d.values())      \n",
    "         \n",
    "meta.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create CS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_op():\n",
    "    op_list = []\n",
    "    df_op = read_excel(xls,'ops',na_filter = False)\n",
    "    for i in df_op.itertuples(index=True):\n",
    "        op = CS.CapabilityStatementRestOperation()\n",
    "        op.name = i.name\n",
    "        ref = FR.FHIRReference()\n",
    "        ref.reference = i.definition if i.definition else f'{canon}OperationDefinition/{i.name}'\n",
    "        print(f'op.definition =  {ref.reference}')    \n",
    "        op.definition =  ref\n",
    "        op.extension = get_conf(i.conf) \n",
    "        op_list.append(op)\n",
    "    return op_list\n",
    "\n",
    "def get_igs():\n",
    "    ig_list = []\n",
    "    df_igs = read_excel(xls,'igs',na_filter = False)\n",
    "    for ig in df_igs.itertuples(index=True):\n",
    "        ig_list.append(ig.uri)\n",
    "    return ig_list\n",
    "\n",
    "\n",
    "cs = CS.CapabilityStatement()\n",
    "cs.id = meta.id\n",
    "cs.url = f'{canon}CapabilityStatement/{meta.id}'\n",
    "cs.version = '0.0.0'  # placeholder changed by build\n",
    "cs.name = snakecase(meta.id)\n",
    "cs.title = f'{pre} {titlecase(meta.id)} {cs.resource_type}'\n",
    "cs.status = 'active'\n",
    "cs.experimental = False\n",
    "cs.date = f_now  # as FHIRDate\n",
    "cs.publisher = publisher\n",
    "cs.contact = [CD.ContactDetail( {\"telecom\" : [ publisher_endpoint ] })]\n",
    "cs.description = meta.description\n",
    "cs.jurisdiction = [f_jurisdiction]\n",
    "cs.kind = 'requirements'\n",
    "cs.fhirVersion = '3.0.1'\n",
    "cs.acceptUnknown = 'both'\n",
    "cs.format = [\n",
    "    \"xml\",\n",
    "    \"json\"\n",
    "  ]\n",
    "cs.patchFormat = [\n",
    "    \"application/json-patch+json\",\n",
    "  ]\n",
    "cs.implementationGuide = meta.ig.split(\",\") + get_igs()\n",
    "rest = CS.CapabilityStatementRest(dict(\n",
    "    mode = meta.mode,\n",
    "    documentation = meta.documentation,\n",
    "    security = dict(\n",
    "        description = meta.security\n",
    "        )\n",
    "    ))\n",
    "rest.operation = get_op()\n",
    "cs.rest = [rest]\n",
    "\n",
    "\n",
    "cs.as_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then the list of IG profiles ( for STU3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = ExcelFile(f'{in_path}{in_file}.xlsx')\n",
    "df = read_excel(xls,'profiles',na_filter = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_map ={}\n",
    "cs.profile = [] \n",
    "for p in df.itertuples(index=True):\n",
    "    print(p.Profile, p.Conformance, p.Name, p.Type)\n",
    "    try: # for mapping stu3 profiles to resources :-(\n",
    "        p_map[p.Type].append(f'[{p.Name}]({p.Profile})')\n",
    "    except KeyError:\n",
    "        p_map[p.Type]=[f'[{p.Name}]({p.Profile})']\n",
    "        \n",
    "    ref = FR.FHIRReference(dict(\n",
    "        reference = p.Profile,\n",
    "        display = p.Name\n",
    "        ))\n",
    "    ref.extension = get_conf(p.Conformance)\n",
    "\n",
    " \n",
    "    cs.profile.append(ref)\n",
    "                                           \n",
    "    \n",
    "pprint(p_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### add Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = read_excel(xls,'resources',na_filter = False)\n",
    "df_i = read_excel(xls,'interactions',na_filter = False)\n",
    "df_sp = read_excel(xls,'sps',na_filter = False)\n",
    "\n",
    "def get_i(type):\n",
    "    int_list = []\n",
    "    for i in df_i.itertuples(index=True):\n",
    "        print(i.code, getattr(i,f'conf_{type}'))\n",
    "        if getattr(i,f'conf_{type}') not in none_list:\n",
    "            int  = CS.CapabilityStatementRestResourceInteraction()\n",
    "            int.code = i.code  \n",
    "            int.extension = get_conf(getattr(i,f'conf_{type}'))    \n",
    "            int_list.append(int.as_json())\n",
    "        \n",
    "    return int_list\n",
    "\n",
    "\n",
    "def get_sp(r_type):\n",
    "    sp_list = []\n",
    "    for i in df_sp.itertuples(index=True):\n",
    "        if i.Resource == r_type:\n",
    "            # print(i.Parameter, i.Resource, i.Conformance)\n",
    "            sp  = CS.CapabilityStatementRestResourceSearchParam()\n",
    "            sp.name = i.Parameter\n",
    "            sp.definition = (f'{canon}SearchParameter/{i.Resource}-{i.Parameter}' if i.Update == 'Y' or i.Exists =='N'\n",
    "                             else f'{fhir_base_url}SearchParameter/{i.Base}-{i.Parameter.split(\"_\")[-1]}')  # removes the '_' for things like _id\n",
    "            # print(sp.definition)\n",
    "            sp.type = i.Type\n",
    "            sp.extension = get_conf(i.Conformance)    \n",
    "            sp_list.append(sp.as_json())\n",
    "    return sp_list\n",
    "\n",
    "\n",
    "def get_conf_str(combo, r_type):\n",
    "    conf_str = ''\n",
    "    for k in df_sp.itertuples(index=True):\n",
    "        if k.Resource == r_type and k.Parameter in combo:\n",
    "            if  k.Conformance == 'MAY' or k.Conformance in none_list:\n",
    "                conf_str = 'MAY'\n",
    "                break\n",
    "            elif k.Conformance == 'SHOULD':\n",
    "                conf_str = 'SHOULD' \n",
    "            elif k.Conformance == 'SHALL' and conf_str not in ['SHALL','MAY']:\n",
    "                conf_str ='SHALL' \n",
    "    return conf_str\n",
    "\n",
    "\n",
    "def get_combo_ext(r_type,combos):\n",
    "    x_list = []\n",
    "    for combo in combos:\n",
    "        # convert to extension\n",
    "        combo_ext = X.Extension()\n",
    "        combo_ext.url = combo_url\n",
    "        combo_conf_ext = get_conf(get_conf_str(combo, r_type))\n",
    "        combo_ext.extension=combo_conf_ext\n",
    "        for param in combo:\n",
    "            req_combo = X.Extension(\n",
    "                dict (\n",
    "                    url = 'required',\n",
    "                    valueString =param\n",
    "                    )\n",
    "                )\n",
    "            combo_ext.extension.append(req_combo)\n",
    "        x_list.append(combo_ext)\n",
    "        # print(x_list)\n",
    "    return x_list\n",
    " \n",
    "    \n",
    "def get_combos(pairs,c_list):\n",
    "    a_list =[]\n",
    "    for i in c_list:\n",
    "        for j in c_list:\n",
    "            #print(f'i={i} j = {j}, i&j= {i&j} i^j= {i^j}')\n",
    "            if i & j and i != j:\n",
    "                #print(f'i={i}, j = {j}, i&j= {i&j},i^j= {i^j} i|j = {i|j}')\n",
    "                if i^j in pairs:\n",
    "                    if i|j not in a_list + c_list:\n",
    "                        a_list.append(i|j)\n",
    "    return a_list\n",
    "    \n",
    "    \n",
    "\n",
    "def get_search_combos(r_type,sp_len):\n",
    "    pairs = []\n",
    "    for k in df_sp.itertuples(index=True):\n",
    "        if k.Resource == r_type:\n",
    "            # print(i.Parameter, i.Resource, i.Conformance)     \n",
    "            for v in k.combo_pairs.split(','):  #get allowed pairs\n",
    "                # print(k.Parameter,v)\n",
    "                if {v,k.Parameter} not in pairs and v not in none_list:\n",
    "                    pairs.append({k.Parameter,v})\n",
    "    # print(pairs)\n",
    "    combo_list = pairs\n",
    "    for j in range(sp_len-1):\n",
    "         combo_list = combo_list + get_combos(pairs,combo_list)\n",
    "    # convert to sorted tuples\n",
    "    combo_list = [sorted(tuple(i)) for i in combo_list]\n",
    "    combo_list = sorted(combo_list)\n",
    "    # print(combo_list)\n",
    "    return combo_list\n",
    "                \n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "rest.resource =  []\n",
    "for r in df.itertuples(index=True):\n",
    "    # print(r.type, r.conformance, r.readHistory)\n",
    "    res = CS.CapabilityStatementRestResource(\n",
    "    dict(\n",
    "        type = r.type,\n",
    "        documentation = r.documentation if r.documentation not in none_list else None,\n",
    "        versioning = r.versioning if r.versioning not in none_list else None,\n",
    "        readHistory = None if r.readHistory is None else r.readHistory == 'True',\n",
    "        updateCreate = None if r.readHistory is None else r.readHistory == 'True',\n",
    "        referencePolicy = r.referencePolicy.split(\",\") if r.referencePolicy not in none_list else [],\n",
    "        interaction = get_i(r.type),\n",
    "        searchParam = get_sp(r.type),\n",
    "        searchInclude = r.searchInclude.split(\",\") if r.searchInclude not in none_list else []\n",
    "        \n",
    "        ) \n",
    "    )\n",
    "    res.extension = get_conf(r.conformance)\n",
    "    print(len(res.searchParam))\n",
    "    combos = get_search_combos(r.type, len(res.searchParam)) # sorted tuples\n",
    "    print(f'{len(combos)} combos = {combos}')\n",
    "    try: #subtract forbidden combos\n",
    "        f_combos = [sorted(i.split(',')) for i in r.forbidden_s_combos.split('|')]   #forbidden combos\n",
    "        print(f' r.forbidden_s_combos.split(\"|\") = {r.forbidden_s_combos.split(\"|\")}, f_combos= {f_combos}')\n",
    "        combos = [i for i in combos if i not in f_combos]\n",
    "    except AttributeError:\n",
    "        pass #forbidden_s_combos is missing\n",
    "    print(f'{len(combos)} combos = {combos}')\n",
    "    res.extension = res.extension + get_combo_ext(r.type,combos) # convert list to  lst of combo extensions\n",
    "\n",
    "    rest.resource.append(res)\n",
    "cs.rest = [rest]\n",
    "    \n",
    "print(dumps(cs.as_json(),indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #validate and write to file\n",
    "\n",
    "print('...validating')\n",
    "r = validate(cs)\n",
    "display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Narrative\n",
    "\n",
    "- Using Jinja2 Template create xhtml for narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = ''\n",
    "in_file = 'STU3capabilitystatement-server.xhtml'\n",
    "\n",
    "\n",
    "def markdown(text, *args, **kwargs):\n",
    "    return commonmark(text, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "env = Environment(\n",
    "    loader=FileSystemLoader(searchpath = in_path),\n",
    "    autoescape=select_autoescape(['html','xml','xhtml','j2','md'])\n",
    "    )\n",
    "\n",
    "env.filters['markdown'] = markdown\n",
    "\n",
    "\n",
    "template = env.get_template(in_file)\n",
    "\n",
    "print(p_map)\n",
    "display(HTML(template.render(cs=cs, p_map=p_map)))\n",
    "rendered = template.render(cs=cs, p_map=p_map)\n",
    "#print(rendered)\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "root = etree.fromstring(rendered, parser=parser)\n",
    "\n",
    "div = (etree.tostring(root[1][0], encoding='unicode', method='html'))\n",
    "narr = N.Narrative()\n",
    "narr.status = 'generated'\n",
    "narr.div = div\n",
    "cs.text = narr\n",
    "\n",
    "\n",
    "#print(dumps(cs.as_json(),indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...validating')\n",
    "r = validate(cs)\n",
    "display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "\n",
    "rjson = dumps(cs.as_json(), indent=3)\n",
    "name =f'capabilitystatement-{cs.id.lower()}'\n",
    "print(name)\n",
    "write_file(name, rjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
