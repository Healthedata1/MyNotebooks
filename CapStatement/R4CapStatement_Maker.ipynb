{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FHIR R4 CapStatement Resource\n",
    "\n",
    "### Outline:\n",
    "\n",
    "- Source excel with requirements\n",
    "- pandas to convert in python Ordered Dict\n",
    "- build json\n",
    "- generate narrative using Jinja2 templates\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Python 3.6 or greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FHIRClient and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhirclient.r4models.fhirabstractbase import FHIRValidationError\n",
    "from fhirclient.r4models import searchparameter as SP\n",
    "from fhirclient.r4models import capabilitystatement as CS\n",
    "from fhirclient.r4models import bundle as B\n",
    "from fhirclient.r4models import narrative as N\n",
    "import fhirclient.models.identifier as I\n",
    "import fhirclient.r4models.identifier as I\n",
    "import fhirclient.r4models.coding as C\n",
    "import fhirclient.r4models.codeableconcept as CC\n",
    "import fhirclient.r4models.fhirdate as D\n",
    "import fhirclient.r4models.extension as X\n",
    "import fhirclient.r4models.contactdetail as CD\n",
    "import fhirclient.r4models.fhirreference as FR\n",
    "from json import dumps, loads, load\n",
    "from requests import get, post, put\n",
    "import os\n",
    "from pathlib import Path\n",
    "from csv import reader as csvreader\n",
    "from IPython.display import display as Display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "from pandas import *\n",
    "from datetime import datetime, date\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "from stringcase import snakecase, titlecase\n",
    "from itertools import zip_longest\n",
    "from openpyxl import load_workbook\n",
    "from commonmark import commonmark\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Assign Global Variables\n",
    "\n",
    "\n",
    "Here is where we assign all the global variables for this example such as the canonical base and project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** Need to update when changing IGs *************************************************\n",
    "fhir_base_url = 'http://hl7.org/fhir/'\n",
    "#pre = \"US-Core\"\n",
    "pre = \"Da Vinci\"\n",
    "#canon = \"http://hl7.org/fhir/us/core/\"  # don't forget the slash  - fix using os.join or path\n",
    "canon = \"http://hl7.org/fhir/us/davinci-notifications/\"  # don't forget the slash  - fix using os.join or path\n",
    "#canon = \"http://hl7.org/fhir/us/davinci-deqm/\"  # don't forget the slash  - fix using os.join or path\n",
    "#ig_folder = 'US-Core'\n",
    "#ig_folder = 'Davinci-Notifications'\n",
    "#ig_folder = 'Davinci-DEQM'\n",
    "#publisher = 'HL7 International - US Realm Steering Committee'\n",
    "#publisher = 'HL7 International - Clinical Decision Support Work Group'\n",
    "publisher = 'HL7 International - Infrascture and Messaging Work Group'\n",
    "'''\n",
    "publisher_endpoint = dict(\n",
    "                        system = 'url',\n",
    "                        value = 'http://www.hl7.org/Special/committees/usrealm/index.cfm'\n",
    "                        )\n",
    "'''\n",
    "'''publisher_endpoint = dict(\n",
    "                        system = 'url',\n",
    "                        value = 'http://www.hl7.org/Special/committees/cds/index.cfm'\n",
    "                        )\n",
    "'''\n",
    "publisher_endpoint = dict(\n",
    "                        system = 'url',\n",
    "                        value = 'http://www.hl7.org/Special/committees/inm/index.cfm'\n",
    "                        )\n",
    "\n",
    "\n",
    "#ig_package_tar_path =  \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/output\"  # !! Change back to US-Core\n",
    "#ig_package_path =  \"//ERICS-AIR-2/ehaas/.fhir/packages/hl7.fhir.us.core.argo#dev\" # !! Change back to r4\n",
    "ig_package_tar_path =  \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Notifications/output\"\n",
    "ig_package_path =  \"//ERICS-AIR-2/ehaas/.fhir/packages/hl7.fhir.us.davinci-notifications#dev\"\n",
    "#ig_package_tar_path =  \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/output\"\n",
    "#ig_package_path =  \"//ERICS-AIR-2/ehaas/.fhir/packages/hl7.fhir.us.davinci-deqm#dev\"\n",
    "#ig_package_path = \"C:/Users/Administrator/Downloads/\"\n",
    "#ig_source_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/source/\" # !! Change back to US-Core\n",
    "#ig_source_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/source/\"\n",
    "ig_source_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Notifications/source/\"\n",
    "#ig_source_path = \"/Users/ehaas/Documents/FHIR/US-Core-R4/source/\"\n",
    "#ig_source_path = ''\n",
    "\n",
    "# spreadsheet source\n",
    "#in_path = '/Users/ehaas/Documents/FHIR/pyfhir/test/'\n",
    "#in_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/source/source_spreadsheets/\"  # !! Change back to US-Core\n",
    "#in_file =\"uscore-server\"\n",
    "#in_file =\"uscore-client\"\n",
    "in_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Notifications/source/resources/source-data/capstatements-spreadsheets/\"\n",
    "in_file =\"alert-initiator\"\n",
    "#in_file =\"alert-receiver\"\n",
    "#in_file =\"query-responder\"\n",
    "#in_file =\"query-requester\"\n",
    "#in_path = \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/source/resources/source-data/\"\n",
    "#in_file = \"DEQM_Capability_Statement_Consumer_Client\"\n",
    "#in_file = \"DEQM_Capability_Statement_Reporter_Client\"\n",
    "#in_file = \"DEQM_Capability_Statement_Consumer_Server\"\n",
    "#in_file = \"DEQM_Capability_Statement_Producer_Client\"\n",
    "#in_file = \"DEQM_Capability_Statement_Producer_Server\"\n",
    "#in_file = \"DEQM_Capability_Statement_Receiver_Server\"\n",
    "#\"\\\\ERICS-AIR-2\\ehaas\\Documents\\FHIR\\Davinci-Alerts\\source\\resources\\source-data\\alert-sender.xlsx\"\n",
    "#'//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Alerts/source/resources/source_data/alert-sender.xlsx'\n",
    "#******************** Need to update when changing IGs *************************************************\n",
    "\n",
    "f_jurisdiction =  CC.CodeableConcept({\n",
    "      \"coding\" : [\n",
    "        {\n",
    "          \"system\" : \"urn:iso:std:iso:3166\",\n",
    "          \"code\" : \"US\"\n",
    "        }\n",
    "      ]\n",
    "    })\n",
    "\n",
    "conf_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-expectation'\n",
    "combo_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-search-parameter-combination'\n",
    "\n",
    "sp_specials = {'us-core-includeprovenance':'http://hl7.org/fhir/us/core/SearchParameter/us-core-includeprovenance'}  # dict to for SP to get right canonicals, may use spreadsheet or package file in future.\n",
    "\n",
    "none_list = ['', ' ', 'none', 'n/a', 'N/A', 'N', 'False']\n",
    "\n",
    "sep_list = (',', ';', ' ', ', ', '; ')\n",
    "\n",
    "f_now = D.FHIRDate(str(date.today()))\n",
    "f_now.as_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conformance Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf(conf='MAY',as_dict=False):\n",
    "    if as_dict:\n",
    "        return [X.Extension(dict(\n",
    "            url = conf_url,\n",
    "            valueCode = conf\n",
    "            )).as_json()]\n",
    "    else:\n",
    "        return [X.Extension(dict(\n",
    "            url = conf_url,\n",
    "            valueCode = conf\n",
    "            ))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** validate Resource ********************************\n",
    "\n",
    "def validate(r):\n",
    "\n",
    "    fhir_test_server = 'http://test.fhir.org/r4'\n",
    "\n",
    "    headers = {\n",
    "    'Accept':'application/fhir+json',\n",
    "    'Content-Type':'application/fhir+json'\n",
    "    }\n",
    "\n",
    "    # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    " \n",
    "    params = dict(\n",
    "      # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    "        )\n",
    "    \n",
    "    #   r = requests.post('https://httpbin.org/post', data = {'key':'value'})\n",
    "    r = post(f'{fhir_test_server}/Questionnaire/$validate', params = params, headers = headers, data = dumps(r.as_json()))\n",
    "    # return r.status_code\n",
    "    # view  output\n",
    "    # return (r.json()[\"text\"][\"div\"])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cap Statement input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first the meta sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = ExcelFile(f'{in_path}{in_file}.xlsx')\n",
    "df = read_excel(xls,'meta',na_filter = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NamedTuple from df to use dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(df.Element, df.Value))\n",
    "meta = namedtuple(\"Meta\", d.keys())(*d.values())      \n",
    "         \n",
    "meta.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create CS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sys_op():\n",
    "    op_list = []\n",
    "    df_op = read_excel(xls,'ops',na_filter = False)\n",
    "    for i in df_op.itertuples(index=True):\n",
    "        if i.type == 'system':\n",
    "            op = CS.CapabilityStatementRestResourceOperation()\n",
    "            op.name = i.name \n",
    "            op.definition = i.definition\n",
    "            op.extension = get_conf(i.conf) \n",
    "            op_list.append(op.as_json())\n",
    "    return op_list\n",
    "\n",
    "\n",
    "def get_rest_ints():\n",
    "    ri_list = []\n",
    "    df_ri = read_excel(xls,'rest_interactions',na_filter = False)\n",
    "    for i in df_ri.itertuples(index=True):\n",
    "        ri = CS.CapabilityStatementRestInteraction()\n",
    "        ri.code = i.code \n",
    "        ri.documentation = i.doc if i.doc not in none_list else None\n",
    "        ri.extension = get_conf(i.conf)\n",
    "        print(ri.as_json())\n",
    "        ri_list.append(ri.as_json())\n",
    "    return ri_list\n",
    "\n",
    "def get_igs():\n",
    "    ig_list = []\n",
    "    df_igs = read_excel(xls,'igs',na_filter = False)\n",
    "    for ig in df_igs.itertuples(index=True):\n",
    "        ig_list.append(ig.uri)\n",
    "    return ig_list # TODO add conformance to this\n",
    "\n",
    "def kebab_to_pascal(word):\n",
    "    return ''.join(x.capitalize() for x in word.split('-'))\n",
    "\n",
    "cs = CS.CapabilityStatement()\n",
    "cs.id = meta.id\n",
    "cs.url = f'{canon}CapabilityStatement/{meta.id}'\n",
    "cs.version = meta.version\n",
    "cs.name = f'{kebab_to_pascal(meta.id)}{cs.resource_type}'\n",
    "cs.title = f'{titlecase(meta.id).replace(\"Us \", \"US \")} {cs.resource_type}'\n",
    "cs.status = 'active'\n",
    "\n",
    "cs.experimental = False\n",
    "cs.date = f_now  # as FHIRDate\n",
    "cs.publisher = publisher\n",
    "cs.contact = [CD.ContactDetail( {\"telecom\" : [ publisher_endpoint ] })]\n",
    "cs.description = meta.description\n",
    "cs.jurisdiction = [f_jurisdiction]\n",
    "cs.kind = 'requirements'\n",
    "cs.fhirVersion = meta.fhirVersion\n",
    "cs.acceptUnknown = 'both'\n",
    "cs.format = [\n",
    "    \"xml\",\n",
    "    \"json\"\n",
    "  ]\n",
    "cs.patchFormat = [\n",
    "    \"application/json-patch+json\",\n",
    "  ]\n",
    "cs.implementationGuide = meta.ig.split(\",\") + get_igs()\n",
    "rest = CS.CapabilityStatementRest(dict(\n",
    "    mode = meta.mode,\n",
    "    documentation = meta.documentation,\n",
    "    security = dict(\n",
    "        description = meta.security\n",
    "        ) if meta.security else None,\n",
    "    interaction = get_rest_ints(),\n",
    "    operation = get_sys_op()\n",
    "    ))\n",
    "cs.rest = [rest]\n",
    "\n",
    "\n",
    "cs.as_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then the list of IG profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = ExcelFile(f'{in_path}{in_file}.xlsx')\n",
    "df = read_excel(xls,'profiles',na_filter = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add Resources\n",
    "\n",
    "- read sheets for resource attributes, interaction attributes,  search attributes, profiles, and combo search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resources = read_excel(xls,'resources',na_filter = False)\n",
    "df_profiles = read_excel(xls,'profiles',na_filter = False)\n",
    "df_i = read_excel(xls,'interactions',na_filter = False)\n",
    "df_sp = read_excel(xls,'sps',na_filter = False)\n",
    "df_combos = read_excel(xls,'sp_combos',na_filter = False)\n",
    "df_op = read_excel(xls,'ops',na_filter = False)\n",
    "\n",
    "\n",
    "def get_i(type):\n",
    "    int_list = []\n",
    "    for i in df_i.itertuples(index=True):\n",
    "        #print(i.code, getattr(i,f'conf_{type}'))\n",
    "        if getattr(i,f'conf_{type}') not in none_list:\n",
    "            int  = CS.CapabilityStatementRestResourceInteraction()\n",
    "            int.code = i.code\n",
    "            try:\n",
    "                int.documentation = getattr(i,f'doc_{type}') if getattr(i,f'doc_{type}') not in none_list else None\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            int.extension = get_conf(getattr(i,f'conf_{type}'))    \n",
    "            int_list.append(int.as_json())\n",
    "        \n",
    "    return int_list\n",
    "\n",
    "\n",
    "def get_sp(r_type):\n",
    "    sp_list = []\n",
    "    for i in df_sp.itertuples(index=True):\n",
    "        if i.base == r_type:\n",
    "            sp  = CS.CapabilityStatementRestResourceSearchParam()\n",
    "            sp.name = i.code\n",
    "            \n",
    "            # TODO need to fix this to reference the package file to reconcile definition to names\n",
    "            if i.code in sp_specials: #special case temp fix for us-core\n",
    "                sp.definition = sp_specials[i.code]\n",
    "            elif i.update == 'Y' or i.exists =='N':\n",
    "                sp.definition = (f'{canon}SearchParameter/{pre.lower()}-{i.base.lower()}-{i.code.split(\"_\")[-1]}')                  \n",
    "            else:  # use base definition\n",
    "                sp.definition = f'{fhir_base_url}SearchParameter/{i.base}-{i.code.split(\"_\")[-1]}'  # removes the '_' for things like _id\n",
    "                                 \n",
    "            # print(sp.definition)\n",
    "                                 \n",
    "            sp.type = i.type\n",
    "            sp.extension = get_conf(i.base_conf)\n",
    "            #print(sp.as_json())                \n",
    "            sp_list.append(sp.as_json())\n",
    "                             \n",
    "    return sp_list\n",
    "\n",
    "\n",
    "def get_combo_ext(r_type,combos):\n",
    "    x_list = []\n",
    "    for combo in combos:\n",
    "        # convert to extension\n",
    "        combo_ext = X.Extension()\n",
    "        combo_ext.url = combo_url\n",
    "        combo_conf_ext = get_conf(combo[1])\n",
    "        combo_ext.extension=combo_conf_ext\n",
    "        for param in combo[0].split(','):\n",
    "            req_combo = X.Extension(\n",
    "                dict (\n",
    "                    url = 'required',\n",
    "                    valueString = param   #http://hl7.org/fhir/us/core/SearchParameter/us-core-patient-family\n",
    "                    )\n",
    "                )\n",
    "            combo_ext.extension.append(req_combo)\n",
    "        x_list.append(combo_ext)\n",
    "        # print(x_list)\n",
    "    return x_list\n",
    "                             \n",
    "def get_op(r_type):\n",
    "    op_list = []\n",
    "    for i in df_op.itertuples(index=True):\n",
    "         if i.type == r_type:\n",
    "            op = CS.CapabilityStatementRestResourceOperation()\n",
    "            op.name = i.name \n",
    "            op.definition = i.definition\n",
    "            op.documentation = i.documentation if i.documentation not in none_list else None\n",
    "            op.extension = get_conf(i.conf) \n",
    "            op_list.append(op.as_json())\n",
    "                           \n",
    "    return op_list \n",
    "\n",
    "rest.resource =  []\n",
    "for r in df_resources.itertuples(index=True):\n",
    "    if not r.type.startswith('!'):\n",
    "        # print(r.type, r.conformance, r.readHistory)\n",
    "        supported_profile = [p.Profile for p in df_profiles.itertuples(index=True) if p.Type == r.type]\n",
    "        #pprint(supported_profile)                         \n",
    "        res = CS.CapabilityStatementRestResource(\n",
    "        dict(\n",
    "            type = r.type,\n",
    "            documentation = r.documentation if r.documentation not in none_list else None,\n",
    "            versioning = r.versioning if r.versioning not in none_list else None,\n",
    "            readHistory = r.readHistory if r.readHistory not in none_list else None,\n",
    "            updateCreate = r.updateCreate if r.updateCreate not in none_list else None,\n",
    "            conditionalCreate = r.conditionalCreate if r.conditionalCreate not in none_list else None,\n",
    "            conditionalRead = r.conditionalRead if r.conditionalRead not in none_list else None,\n",
    "            conditionalUpdate = r.conditionalUpdate if r.conditionalUpdate not in none_list else None,\n",
    "            conditionalDelete = r.conditionalDelete if r.conditionalDelete not in none_list else None,\n",
    "            referencePolicy = [x for x in r.referencePolicy.split(\",\") if x],\n",
    "            searchInclude =  [x for x in r.shall_include.split(\",\") + r.should_include.split(\",\") if x],\n",
    "            searchRevInclude =  [x for x in r.shall_revinclude.split(\",\") + r.should_revinclude.split(\",\") if x],\n",
    "            interaction = get_i(r.type),\n",
    "            searchParam = get_sp(r.type),\n",
    "            operation = get_op(r.type),\n",
    "            #profile = f'{fhir_base_url}StructureDefinition/{r.type}',\n",
    "            supportedProfile = supported_profile,\n",
    "            )\n",
    "        )\n",
    "        res.extension = get_conf(r.conformance)\n",
    "        combos = {(i.combo,i.combo_conf) for i in df_combos.itertuples(index=True) if i.base == r.type}\n",
    "        res.extension = res.extension + get_combo_ext(r.type,combos) # convert list to  lst of combo extension\n",
    "                            \n",
    "                                 \n",
    "        '''\n",
    "        #TODO add in conformance expectations for primitives \n",
    "        #need to convert to dict since model can't handle primitive extensions\n",
    "\n",
    "        resttype_dict = res.as_json()\n",
    "\n",
    "        for i in ['Include','RevInclude']:\n",
    "            element = f'_search{i}'\n",
    "\n",
    "            resttype_dict[element] = []\n",
    "            print(element)\n",
    "            for expectation in ['should', 'shall']: # list all should includes first\n",
    "                sp_attr = f'{expectation}_{i.lower()}'\n",
    "                print(sp_attr) \n",
    "                includes = getattr(r,sp_attr).split(',')\n",
    "                print(includes)\n",
    "\n",
    "                for include in includes:\n",
    "                    if include not in none_list:             \n",
    "                        print(include)\n",
    "                        conf = get_conf(expectation.upper(),as_dict=True)\n",
    "                        print(conf)\n",
    "                        conf = conf\n",
    "                        print(conf)        \n",
    "                        resttype_dict[element].append(conf)\n",
    "\n",
    "            if not resttype_dict[element]:\n",
    "                    del(resttype_dict[element])\n",
    "\n",
    "        print(dumps(resttype_dict, indent = 4))\n",
    "        res = CS.CapabilityStatementRestResource(resttype_dict, strict = False)\n",
    "        print('++++++++++++++++RES.__dict__+++++++++++++++++++')\n",
    "        print(dumps(res._searchRevInclude, indent = 4))\n",
    "        '''                               \n",
    "                                 \n",
    "        rest.resource.append(res)\n",
    "\n",
    "rest.resource =  sorted(rest.resource,key = lambda x: x.type)  # sort resources                         \n",
    "cs.rest = [rest]\n",
    "    \n",
    "print(dumps(cs.as_json(),indent=3))    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model to dict and add extensions to primitives **Deactivated ( marked a raw block ) since will need to use dict in subsuquent steps."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "#add in conformance expectations for primitives \n",
    "#convert to dict since model can't handle primitive extensions\n",
    "\n",
    "resttype_dict = res.as_json()\n",
    "\n",
    "for i in ['Include','RevInclude']:\n",
    "    element = f'_search{i}'\n",
    "\n",
    "    resttype_dict[element] = []\n",
    "    print(element)\n",
    "    for expectation in ['should', 'shall']: # list all should includes first\n",
    "        sp_attr = f'{expectation}_{i.lower()}'\n",
    "        print(sp_attr) \n",
    "        includes = getattr(r,sp_attr).split(',')\n",
    "        print(includes)\n",
    "\n",
    "        for include in includes:\n",
    "            if include not in none_list:             \n",
    "                print(include)\n",
    "                conf = get_conf(expectation.upper(),as_dict=True)\n",
    "                print(conf)\n",
    "                conf = conf\n",
    "                print(conf)        \n",
    "                resttype_dict[element].append(conf)\n",
    "\n",
    "    if not resttype_dict[element]:\n",
    "            del(resttype_dict[element])\n",
    "\n",
    "print(resttype_dict)\n",
    "\n",
    "print(dumps(cs.as_json(),indent=3))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #validate and write to file\n",
    "\n",
    "print('...validating')\n",
    "r = validate(cs)\n",
    "display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Narrative\n",
    "\n",
    "- Using Jinja2 Template create xhtml for narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First: Get spec_internal from package.tgz a json file which includes canonical to local relative page links\n",
    "\n",
    "Note for this to work you have to have a working build that already contains all the needed artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def get_si(path):\n",
    "    with tarfile.open(f'{path}/package.tgz', mode='r') as tf:\n",
    "        #pprint(tf.getnames())\n",
    "        f = tf.extractfile('other/spec.internals')\n",
    "        r = f.read()\n",
    "        return(loads(r))\n",
    "\n",
    "def get_si2(path):\n",
    "    with open(f'{path}/other/spec.internals', 'r', encoding='utf-8-sig') as f:\n",
    "        r = f.read()\n",
    "        return(loads(r, encoding = 'utf-8'))\n",
    "\n",
    "try:      \n",
    "    si = get_si(ig_package_tar_path)\n",
    "except FileNotFoundError:\n",
    "    si = get_si2(ig_package_path) # get from package (json) file in local .fhir directory\n",
    "       \n",
    "path_map = si['paths']\n",
    "path_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then Use Jinja2 template to create narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = ''\n",
    "in_file = 'R4capabilitystatement-server.j2'\n",
    "\n",
    "def markdown(text, *args, **kwargs):\n",
    "    return commonmark(text, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "env = Environment(\n",
    "    loader=FileSystemLoader(searchpath = in_path),\n",
    "    autoescape=select_autoescape(['html','xml','xhtml','j2','md'])\n",
    "    )\n",
    "\n",
    "env.filters['markdown'] = markdown\n",
    "\n",
    "\n",
    "template = env.get_template(in_file)\n",
    "\n",
    "sp_map = {sp.code:sp.type for sp in df_sp.itertuples(index=True)}\n",
    "pname_map = {p.Profile:p.Name for p in df_profiles.itertuples(index=True)}\n",
    "pprint(pname_map)\n",
    "\n",
    "rendered = template.render(cs=cs, path_map=path_map, pname_map = pname_map, sp_map =sp_map )\n",
    "\n",
    "display(HTML(rendered))\n",
    "\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "root = etree.fromstring(rendered, parser=parser)\n",
    "\n",
    "div = (etree.tostring(root[1][0], encoding='unicode', method='html'))\n",
    "narr = N.Narrative()\n",
    "narr.status = 'generated'\n",
    "narr.div = div\n",
    "cs.text = narr\n",
    "\n",
    "\n",
    "#print(dumps(cs.as_json(),indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...validating')\n",
    "r = validate(cs)\n",
    "display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "print('...........saving to file............')\n",
    "#save in ig_source folder\n",
    "path = Path.cwd() / ig_source_path / 'resources' / f'capabilitystatement-{cs.id.lower()}.json'\n",
    "path.write_text(dumps(cs.as_json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
