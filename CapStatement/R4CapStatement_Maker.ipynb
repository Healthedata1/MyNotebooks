{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FHIR R4 CapStatement Resource\n",
    "\n",
    "\n",
    "### Outline:\n",
    "\n",
    "- Source excel with requirements\n",
    "- pandas to convert in python Ordered Dict\n",
    "- build json\n",
    "- generate narrative using Jinja2 templates\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Python 3.6 or greater\n",
    "- Need to run after conformance resources added to IG and package list created.\n",
    "\n",
    "### Options: Use global varables below to turn on and off\n",
    "\n",
    "- add narrative to resources if not using liquid script or IG publisher default\n",
    "- add ms-table \n",
    "- validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP1: Choose Source Spreadsheet to use\n",
    "\n",
    "*note:  Jupyteralab and widgets issues: see https://stackoverflow.com/questions/4\n",
    "9542417/how-to-get-ipywidgets-working-in-jupyter-lab for solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** NEED TO UPDATE WHEN Adding new IGS ************************************************\n",
    "\n",
    "from os import name as os_name\n",
    "my_base = '/Users/ehaas/' ###if os_name == 'posix' else '//ERICS-AIR-2/ehaas/'\n",
    "\n",
    "\n",
    "in_path_list = [\n",
    "    \n",
    "        \"---pick one below---\",\n",
    "        # \"Documents/Python/MyNotebooks/CapStatement/temp_source_spreadsheets/test-spreadsheet.xlsx\",\n",
    "         \"Documents/FHIR/US-Core/input/resources_spreadsheets/uscore-client.xlsx\",\n",
    "         \"Documents/FHIR/US-Core/input/resources_spreadsheets/uscore-server.xlsx\",\n",
    "         \"Documents/FHIR/davinci-alerts/input/resources-spreadsheets/alert-initiator.xlsx\",\n",
    "         \"Documents/FHIR/davinci-alerts/input/resources-spreadsheets/alert-receiver.xlsx\",\n",
    "         \"Documents/FHIR/davinci-alerts/input/resources-spreadsheets/notification-forwarder.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_Consumer_Client.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_Consumer_Server.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_GIC_Receiver_Server.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_GIC_Reporter_Client.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_Producer_Client.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_Producer_Server.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_Receiver_Server.xlsx\",\n",
    "        # \"Documents/Python/Jupyter/MyNotebooks/CapStatement/temp_source_spreadsheets/2022-10-26_DEQM/DEQM_Capability_Statement_Reporter_Client.xlsx\",\n",
    "        #   \"Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_GIC_Receiver_Server.xlsx\",\n",
    "        #  'C:/Users/Administrator/Downloads/plan-net-server.xlsx',\n",
    "        'Documents/FHIR/Davinci-ecdx/input/resources-spreadsheet/data-source-client.xlsx',\n",
    "        'Documents/FHIR/Davinci-ecdx/input/resources-spreadsheet/data-source-server.xlsx',\n",
    "        'Documents/FHIR/Davinci-ecdx/input/resources-spreadsheet/data-consumer-client.xlsx',\n",
    "        'Documents/FHIR/Davinci-ecdx/input/resources-spreadsheet/data-consumer-server.xlsx',\n",
    "        # 'Documents/FHIR/Argo-PL/input/resources-spreadsheet/client.xlsx',\n",
    "        # 'Documents/FHIR/Argo-PL/input/resources-spreadsheet/server.xlsx',   \n",
    "        ]\n",
    "\n",
    "\n",
    "# ----------spreadsheet source---------------\n",
    "from IPython.display import display as Display, HTML, Markdown, Javascript\n",
    "from ipywidgets import Dropdown\n",
    "menu = Dropdown(\n",
    "       options=[my_base + x for x in in_path_list],\n",
    "       description='Choose Spreadsheet Source file',\n",
    "       style = {'description_width': 'initial',},\n",
    "       layout={'width': 'initial'},\n",
    "        )\n",
    "\n",
    "\n",
    "menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP2:  *CLICK HERE* and then 'Select Run Selected Cell and All Below'  from menu bar to continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = menu.value\n",
    "xls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FHIRClient and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhir.resources import construct_fhir_element\n",
    "from json import dumps, loads\n",
    "from yaml import load, SafeLoader\n",
    "from requests import get, post, put\n",
    "from pathlib import Path\n",
    "from IPython.display import display as Display, HTML, Markdown, Javascript\n",
    "import ipywidgets as widgets\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "from pandas import *\n",
    "from datetime import datetime, date, timezone, timedelta\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "from stringcase import snakecase, titlecase\n",
    "from commonmark import commonmark\n",
    "# import markdown\n",
    "from htmlmin import minify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Assign Global Variables\n",
    "\n",
    "Here is where we assign all the global variables for this example such as the canonical base and project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhir_base_url = 'http://hl7.org/fhir/'\n",
    "f_jurisdiction =  construct_fhir_element('CodeableConcept',{\n",
    "      \"coding\" : [\n",
    "        {\n",
    "          \"system\" : \"urn:iso:std:iso:3166\",\n",
    "          \"code\" : \"US\"\n",
    "        }\n",
    "      ]\n",
    "    })\n",
    "\n",
    "conf_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-expectation'\n",
    "combo_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-search-parameter-combination'\n",
    "sp_specials = {'us-core-includeprovenance':'http://hl7.org/fhir/us/core/SearchParameter/us-core-includeprovenance'}  # dict to for SP to get right canonicals, may use spreadsheet or package file in future.\n",
    "\n",
    "none_list = ['', ' ', 'none', 'n/a', 'N/A', 'N', 'False', None,'!']\n",
    "\n",
    "sep_list = (',', ';', ' ', ', ', '; ')\n",
    "\n",
    "\n",
    "timezone_offset = -8.0  # Pacific Standard Time (UTCâˆ’08:00)\n",
    "tzinfo = timezone(timedelta(hours=timezone_offset))\n",
    "f_now = datetime.now(tzinfo)\n",
    "f_now\n",
    "validate_me = False\n",
    "add_ms_references_summary = False\n",
    "add_narrative = True #False  # add narrative to resources if not using liquid script or IG publisher default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To PascalCase Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kebab_to_pascal(word):\n",
    "    return ''.join(x.capitalize() for x in word.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Simple Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_attr(v=None):\n",
    "    if v and v not in none_list:\n",
    "        return v\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set List Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_attr_list(v=None):\n",
    "    if v:\n",
    "        return [i for i in v.split(\",\")]\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conformance Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf(conf='MAY',as_dict=False):\n",
    "    if as_dict:\n",
    "        return [construct_fhir_element('Extension',dict(\n",
    "            url = conf_url,\n",
    "            valueCode = conf\n",
    "            )).json()]\n",
    "    else:\n",
    "        return [construct_fhir_element('Extension',dict(\n",
    "            url = conf_url,\n",
    "            valueCode = conf if conf else \"MAY\"\n",
    "            ))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primitive Conformance Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prim_ext(conf=None):\n",
    "    if not set(conf).issubset(none_list):\n",
    "        conf_list = []\n",
    "        try: # is comma sep string\n",
    "            conf = conf.split(',')\n",
    "        except AttributeError: # is list\n",
    "            pass         \n",
    "        for i in conf:\n",
    "            if i not in none_list:\n",
    "                conf_ext = construct_fhir_element('FHIRPrimitiveExtension', dict(\n",
    "                    extension = get_conf(conf=i),\n",
    "                    ))\n",
    "            else:\n",
    "                conf_ext = None\n",
    "            conf_list.append(conf_ext)\n",
    "        \n",
    "        return conf_list\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addin Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_addin_ext(py_ext, json_ext):            \n",
    "    print(py_ext)\n",
    "    if json_ext:   # ie not ''\n",
    "        addin_ext = construct_fhir_element('Extension',loads(json_ext))            \n",
    "        # addin_ext.extension =  get_conf('SHALL') violates invariant   - DONT USE           \n",
    "        print(addin_ext)                 \n",
    "        py_ext.append(addin_ext) # add in other extensions\n",
    "    print(py_ext)\n",
    "    return py_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** validate Resource ********************************\n",
    "\n",
    "def validate(r):\n",
    "\n",
    "    #fhir_test_server = 'http://test.fhir.org/r4'\n",
    "    # fhir_test_server = 'http://hapi.fhir.org/baseR4'\n",
    "    fhir_test_server = 'http://wildfhir4.aegis.net/fhir4-0-1'\n",
    "    \n",
    "    headers = {\n",
    "    'Accept':'application/fhir+json',\n",
    "    'Content-Type':'application/fhir+json',\n",
    "    }\n",
    "\n",
    "    # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    " \n",
    "    params = dict(\n",
    "      # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    "        )\n",
    "    \n",
    "    #   r = requests.post('https://httpbin.org/post', data = {'key':'value'})\n",
    "    r = post(f'{fhir_test_server}/CapabilityStatement/$validate', params = params, headers = headers, data = r.json().encode('utf-8'))\n",
    "    # return r.status_code\n",
    "    # view  output\n",
    "    # return (r.json()[\"text\"][\"div\"])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cap Statement input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to convert to dataframe series to namedtuple for easy peasy dot notation use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first the config data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_excel(xls,'config',na_filter = False,index_col=0)  # use the index_col = 0 for setting the first rwo as the index\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assign globals e.g. publisher parameter etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.[Column].[row] to get a value df.loc[[row],[Column]] or df.at[[column],[col]] works too\n",
    "df.Value.source #, df.loc['source','Value'], df.at['source' ,'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ig_source_path = df.Value.source\n",
    "ig_package_tar_path =  df.Value.packagepath  # e.g. : https://build.fhir.org/ig/HL7/davinci-alerts/package.tgz  consider using the ig resource instead since this may out of synch with latest changes\n",
    "\n",
    "# --------- ig specific variable -------------------\n",
    "# get these from the ig.yaml I create in the input/data folder ---\n",
    "# --- !!! need to successfully run Sushi to build the IG resource first!!! ---\n",
    "ig_resource_path = Path(ig_source_path) / \"data\" / \"ig.yml\"  #e.g.: /Users/ehaas/Documents/FHIR/US-Core/temp/pages/_data/resources.json\n",
    "ig_resource = load(ig_resource_path.read_text(), Loader=SafeLoader)\n",
    "ig_version = ig_resource['version']\n",
    "canon = ig_resource['url'].split('ImplementationGuide')[0]\n",
    "publisher = ig_resource['publisher']\n",
    "pre = df.Value.pre  # for Titles\n",
    "\n",
    "\n",
    "# canon = df.Value.canon # don't forget the slash  - fix using os.join or path\n",
    "#\n",
    "publisher = df.Value.publisher\n",
    "#\n",
    "publisher_endpoint = dict(\n",
    "                    system = ig_resource['contact'][0]['telecom'][0]['system'],\n",
    "                    value = ig_resource['contact'][0]['telecom'][0]['value'],\n",
    "                  )\n",
    "\n",
    "\n",
    "print(f'''ig_source_path = {ig_source_path}\n",
    "ig_package_tar_path  = {ig_package_tar_path}\n",
    "ig_resource_path = {ig_resource_path}\n",
    "ig_version = {ig_version}\n",
    "canonical = {canon}\n",
    "pre = {pre}\n",
    "publisher = {publisher}\n",
    "publisher_endpoint = {publisher_endpoint}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the meta sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_excel(xls,'meta',na_filter = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NamedTuple from df to use dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(df.Element, df.Value))\n",
    "meta = namedtuple(\"Meta\", d.keys())(*d.values())      \n",
    "         \n",
    "meta.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create CS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = construct_fhir_element('CapabilityStatement',dict(\n",
    "id = meta.id,\n",
    "url = f'{canon}CapabilityStatement/{meta.id}',\n",
    "version = meta.version,\n",
    "name = f'{kebab_to_pascal(meta.id)}CapabilityStatement',\n",
    "title = f'{titlecase(meta.id).replace(\"Us \", \"US \")} CapabilityStatement',\n",
    "status = 'active',\n",
    "experimental = False,\n",
    "date = f_now, # as FHIRDate\n",
    "publisher = publisher,\n",
    "contact = [construct_fhir_element('ContactDetail', {\"telecom\" : [ publisher_endpoint ] })],\n",
    "description = meta.description,\n",
    "jurisdiction = [f_jurisdiction],\n",
    "kind = 'requirements',\n",
    "fhirVersion = meta.fhirVersion,\n",
    "format = set_attr_list(meta.format),\n",
    "format__ext = get_prim_ext(meta.format_conf),\n",
    "patchFormat = set_attr_list(meta.patchFormat),\n",
    "patchFormat__ext = get_prim_ext(meta.patchFormat_conf),\n",
    "))\n",
    "\n",
    "print(cs.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sys_op():\n",
    "    op_list = []\n",
    "    df_op = read_excel(xls,'ops',na_filter = False)\n",
    "    for i in df_op.itertuples(index=True):\n",
    "        if i.type == 'system':\n",
    "            op = construct_fhir_element('CapabilityStatementRestResourceOperation', dict(\n",
    "            #op = CS.CapabilityStatementRestResourceOperation()\n",
    "            name = i.name,\n",
    "            definition = i.definition,\n",
    "            documentation = i.documentation if i.documentation not in none_list else None,\n",
    "            extension = get_conf(i.conf), \n",
    "            ))\n",
    "            op_list.append(op.json())\n",
    "    return op_list if op_list else None\n",
    "\n",
    "\n",
    "def get_rest_ints():\n",
    "    ri_list = []\n",
    "    df_ri = read_excel(xls,'rest_interactions',na_filter = False)\n",
    "    for i in df_ri.itertuples(index=True):\n",
    "        ri = construct_fhir_element('CapabilityStatementRestInteraction', dict(\n",
    "        code = i.code,\n",
    "        documentation = i.doc if i.doc not in none_list else None,\n",
    "        extension = get_conf(i.conf),\n",
    "        ))                         \n",
    "        print(ri.json(indent=2))\n",
    "        ri_list.append(ri.json())        \n",
    "    return ri_list  if ri_list else None\n",
    "\n",
    "rest = construct_fhir_element('CapabilityStatementRest',(dict(\n",
    "    mode = meta.mode,\n",
    "    documentation = meta.documentation,\n",
    "    security = dict(\n",
    "        description = meta.security\n",
    "        ) if meta.security else None,\n",
    "    interaction = get_rest_ints(),\n",
    "    operation = get_sys_op()\n",
    "    )))\n",
    "                              \n",
    "cs.rest = [rest]\n",
    "\n",
    "print(cs.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in IG, and Capstatements and their conformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_igs = read_excel(xls,'igs',na_filter = False)\n",
    "cs.implementationGuide = set_attr([ig.canonical for ig in df_igs.itertuples(index=True) if '!' not in ig.name])\n",
    "#print([ig.conformance for ig in df_igs.itertuples(index=True) if ig.imports not in none_list])\n",
    "cs.implementationGuide__ext = get_prim_ext([ig.conformance for ig in df_igs.itertuples(index=True) if '!' not in ig.name])\n",
    "\n",
    "df_capstatements = read_excel(xls,'capstatements',na_filter = False)\n",
    "cs.imports = set_attr([ig.canonical for ig in df_capstatements.itertuples(index=True) if ig.imports not in none_list])\n",
    "cs.imports__ext = get_prim_ext([ig.conformance for ig in df_capstatements.itertuples(index=True) if ig.imports not in none_list])\n",
    "cs.instantiates = set_attr([ig.canonical for ig in df_capstatements.itertuples(index=True) if ig.instantiates not in none_list])\n",
    "cs.instantiates__ext = get_prim_ext([ig.conformance for ig in df_capstatements.itertuples(index=True) if ig.instantiates not in none_list])\n",
    "\n",
    "print(cs.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add Resources\n",
    "\n",
    "- read sheets for resource attributes, interaction attributes,  search attributes, profiles, and combo search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resources = read_excel(xls,'resources',na_filter = False)\n",
    "df_resources = df_resources[df_resources.type.str[0] != '!']\n",
    "df_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profiles = read_excel(xls,'profiles',na_filter = False)  #df1 = df[df.Hostname.str[0] != \"abc\"]\n",
    "df_profiles = df_profiles[df_profiles.Profile.str[0] != '!']\n",
    "df_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = read_excel(xls,'interactions',na_filter = False)\n",
    "df_sp = read_excel(xls,'sps',na_filter = False)\n",
    "df_combos = read_excel(xls,'sp_combos',na_filter = False)\n",
    "df_op = read_excel(xls,'ops',na_filter = False)\n",
    "\n",
    "\n",
    "def get_i(type):\n",
    "    int_list = []\n",
    "    for i in df_i.itertuples(index=True):\n",
    "        #print(i.code, getattr(i,f'conf_{type}'))\n",
    "        if getattr(i,f'conf_{type}') not in none_list:\n",
    "            try:\n",
    "                documentation = getattr(i,f'doc_{type}') if getattr(i,f'doc_{type}') not in none_list else None\n",
    "            except AttributeError:\n",
    "                documentation = None\n",
    "            int  = construct_fhir_element('CapabilityStatementRestResourceInteraction', dict(\n",
    "            code = i.code,\n",
    "            documentation = documentation,\n",
    "            extension = get_conf(getattr(i,f'conf_{type}')),\n",
    "            ))\n",
    "            int_list.append(int.json()),               \n",
    "    return int_list if int_list else None\n",
    "\n",
    "\n",
    "def get_sp(r_type):\n",
    "    sp_list = []\n",
    "    for i in df_sp.itertuples(index=True):\n",
    "        if i.base == r_type:\n",
    "            # TODO need to fix this to reference the package file to reconcile definition to names\n",
    "            if i.code in sp_specials: #special case temp fix for us-core\n",
    "                definition = sp_specials[i.code]\n",
    "            elif i.update == 'Y' or i.exists =='N':\n",
    "                definition = f'{canon}SearchParameter/{pre.lower()}-{i.base.lower()}-{i.code.lower().replace(\"_\",\"\")}'                  \n",
    "            elif i.code.startswith('_'): #common sp\n",
    "                definition = f'{fhir_base_url}SearchParameter/{i.code.replace(\"_\",\"Resource-\")}'\n",
    "            else:  # use base definition\n",
    "                definition = f'{fhir_base_url}SearchParameter/{i.base}-{i.code}'\n",
    "            # print(definition)\n",
    "            \n",
    "            sp  = construct_fhir_element('CapabilityStatementRestResourceSearchParam', dict(\n",
    "            name = i.code,\n",
    "            definition = definition,\n",
    "            documentation = i.documentation if i.documentation not in none_list else None,               \n",
    "            type = i.type,\n",
    "            extension = get_conf(i.base_conf),\n",
    "            ))\n",
    "            #print(sp.json())                \n",
    "            sp_list.append(sp.json())                            \n",
    "    return sp_list if sp_list else None \n",
    "\n",
    "\n",
    "def get_combo_ext(r_type,combos):\n",
    "    x_list = []\n",
    "    for combo in combos:\n",
    "        # convert to extension\n",
    "        combo_ext = construct_fhir_element('Extension', dict (\n",
    "        url = combo_url,\n",
    "        extension=get_conf(combo[1]),\n",
    "        ))\n",
    "        for param in combo[0].split(','):\n",
    "            req_combo = construct_fhir_element('Extension', dict (\n",
    "                    url = 'required',\n",
    "                    valueString = param,   #http://hl7.org/fhir/us/core/SearchParameter/us-core-patient-family\n",
    "                ))\n",
    "            combo_ext.extension.append(req_combo)\n",
    "        x_list.append(combo_ext)\n",
    "        # print(x_list)\n",
    "    return x_list\n",
    "    \n",
    "def get_op(r_type):\n",
    "    op_list = []\n",
    "    for i in df_op.itertuples(index=True):\n",
    "         if i.type == r_type:\n",
    "            op = construct_fhir_element('CapabilityStatementRestResourceOperation', dict(\n",
    "            name = i.name, \n",
    "            definition = i.definition,\n",
    "            documentation = i.documentation if i.documentation not in none_list else None,\n",
    "            extension = get_conf(i.conf),\n",
    "            ))\n",
    "            try:                     \n",
    "                op.extension =  get_addin_ext(op.extension, i.ext)\n",
    "            except AttributeError:\n",
    "                print(\"---- no addin extensions found-----\")\n",
    "            op_list.append(op.json())                           \n",
    "    return op_list if op_list else None \n",
    "\n",
    "\n",
    "rest.resource =  []\n",
    "for r in df_resources.itertuples(index=True):\n",
    "    # print(r.type, r.conformance, r.readHistory\n",
    "    supported_profile = [f'{p.Profile}{f\"|{cs.version}\" if canon in p.Profile else \"\"}' for p in df_profiles.itertuples(index=True) if p.Type == r.type]\n",
    "    supported_profile_ext = get_prim_ext([p.Conformance for p in df_profiles.itertuples(index=True) if p.Type == r.type])\n",
    "    #pprint(supported_profile)                         \n",
    "    res = construct_fhir_element('CapabilityStatementRestResource', dict(\n",
    "        type = r.type,\n",
    "        documentation = set_attr(r.documentation),\n",
    "        versioning = set_attr(r.versioning),\n",
    "        readHistory = set_attr(r.readHistory),\n",
    "        updateCreate = set_attr(r.updateCreate),\n",
    "        conditionalCreate = set_attr(r.conditionalCreate),\n",
    "        conditionalRead = set_attr(r.conditionalRead),\n",
    "        conditionalUpdate = set_attr(r.conditionalUpdate),\n",
    "        conditionalDelete = set_attr(r.conditionalDelete),\n",
    "        referencePolicy = set_attr_list(r.referencePolicy),\n",
    "        referencePolicy__ext = get_prim_ext(r.referencePolicy_conf),\n",
    "        searchInclude = set_attr_list(r.include),\n",
    "        searchInclude__ext = get_prim_ext(r.include_conf),\n",
    "        searchRevInclude = set_attr_list(r.revinclude),\n",
    "        searchRevInclude__ext = get_prim_ext(r.revinclude_conf),\n",
    "        interaction = get_i(r.type),\n",
    "        searchParam = get_sp(r.type),\n",
    "        operation = get_op(r.type),\n",
    "        profile = set_attr(r.profile),\n",
    "        supportedProfile = supported_profile if supported_profile else None,\n",
    "        supportedProfile__ext = supported_profile_ext\n",
    "        )\n",
    "    )\n",
    "    res.extension = get_conf(r.conformance)\n",
    "    combos = {(i.combo,i.combo_conf) for i in df_combos.itertuples(index=True) if i.base == r.type}\n",
    "    res.extension = res.extension + get_combo_ext(r.type,combos) # convert list to  lst of combo extension                              \n",
    "    rest.resource.append(res)\n",
    "\n",
    "rest.resource =  sorted(rest.resource,key = lambda x: x.type)  # sort resources                         \n",
    "cs.rest = [rest]\n",
    "    \n",
    "# print(cs.json(indent=2))          \n",
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #validate and write to file\n",
    "if validate_me:\n",
    "    print('...validating')\n",
    "    r = validate(cs)\n",
    "    display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Narrative\n",
    "\n",
    "- Using Jinja2 Template create xhtml for narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(add_narrative):\n",
    "    #### First: Get spec_internal from package.tgz a json file which includes canonical to local relative page links\n",
    "    #### Note for this to work you have to have a working build that already contains all the needed artifacts.\n",
    "    import tarfile\n",
    "    package_path = Path.cwd() / 'tarfiles'/'package.tgz'  #get_si(path)\n",
    "    print(package_path)\n",
    "    def get_si(package_path):\n",
    "        with tarfile.open(package_path, mode='r') as tf:\n",
    "            # pprint(tf.getnames())\n",
    "            f = tf.extractfile('package/other/spec.internals')\n",
    "            r = f.read()\n",
    "            return (loads(r))\n",
    "\n",
    "        \n",
    "    def get_si3(path):\n",
    "        tf = get(path)\n",
    "        if tf.status_code == 200:\n",
    "            # print(f'get tarfile from {ig_package_tar_path}')\n",
    "            return tf\n",
    "\n",
    "    # \"e.g. https://build.fhir.org/ig/HL7/davinci-deqm/package.tgz\" \n",
    "    try:\n",
    "        # print(f'get tarfile from {ig_package_tar_path}')  \n",
    "        tf= get_si3(ig_package_tar_path) # get from remote server\n",
    "\n",
    "    except:\n",
    "        print(\"run build in auto-builder first and check remote package file\")\n",
    "        # print(f\"use local package file from build file  = {ig_source_path.replace('/input/', '/output/')}package.tgz\")\n",
    "        # package_path = f\"{ig_source_path.replace('/input/', '/output/')}package.tgz\"\n",
    "        \n",
    "    else:\n",
    "        print(f'get tarfile from {ig_package_tar_path}') \n",
    "        package_path.write_bytes(tf.content)    #save in temp file\n",
    "\n",
    "    si = get_si(package_path) #unpack from file\n",
    "\n",
    "    path_map = si['paths']\n",
    "    # print(f'path_map = {dumps(path_map, indent=2)}')\n",
    "\n",
    "\n",
    "\n",
    "    #### Then Use Jinja2 template to create narrative\n",
    "\n",
    "    in_path = ''\n",
    "    in_file = 'R4capabilitystatement-server.j2'\n",
    "    print(cs.date)\n",
    "    # if add_ms_references_summary: # get Must Support references from ms_references module if available to create summary table of required references\n",
    "    #     import ms_references\n",
    "    #     ms_references_summary = ms_references.get_references_summary()\n",
    "    # else:\n",
    "    #     print('No ms_references module found')\n",
    "    #     ms_references_summary = None\n",
    "\n",
    "    def markdown(text, *args, **kwargs):\n",
    "        return commonmark(text, *args, **kwargs)\n",
    "\n",
    "    env = Environment(\n",
    "        loader=FileSystemLoader(searchpath = in_path),\n",
    "        autoescape=select_autoescape(['html','xml','xhtml','j2','md'],),\n",
    "        trim_blocks = True,\n",
    "        lstrip_blocks = True,\n",
    "        )\n",
    "\n",
    "    env.filters['markdown'] = markdown\n",
    "\n",
    "    # env.filters['markdown'] = lambda text: markdown.markdown(text, extensions=['extra'])\n",
    "\n",
    "    template = env.get_template(in_file)\n",
    "\n",
    "    sp_map = {sp.code:sp.type for sp in df_sp.itertuples(index=True)}\n",
    "    pname_map = {p.Profile:p.Name for p in df_profiles.itertuples(index=True)}\n",
    "    # print(f'pname_map = {pname_map}')\n",
    "\n",
    "\n",
    "    purl_map = {p.Profile:p.url if p.url not in none_list else p.Profile for p in df_profiles.itertuples(index=True)}\n",
    "\n",
    "    igname_map = {ig.canonical:ig.name for ig in df_igs.itertuples(index=True)}\n",
    "    igurl_map = {ig.canonical:ig.url if ig.url not in none_list else ig.canonical for ig in df_igs.itertuples(index=True)}\n",
    "    csname_map = {cs.canonical:cs.name for cs in df_capstatements.itertuples(index=True)}\n",
    "    csurl_map = {cs.canonical:cs.url if cs.url not in none_list else cs.canonical for cs in df_capstatements.itertuples(index=True)}\n",
    "    # print(csurl_map)\n",
    "    # print([i for i in df_capstatements.itertuples(index=True)])\n",
    "    rendered = template.render(cs=cs, path_map=path_map, pname_map=pname_map, purl_map=purl_map, sp_map=sp_map, \n",
    "                            csname_map=csname_map, csurl_map=csurl_map, igname_map=igname_map, igurl_map=igurl_map,) # ms_references_summary = ms_references_summary,)\n",
    "    # print(rendered)\n",
    "\n",
    "\n",
    "\n",
    "    ### Minify the xhtml\n",
    "\n",
    "    def x_minify(xhtml):\n",
    "        h_min=minify(xhtml, remove_optional_attribute_quotes=False, remove_comments=True)\n",
    "        x_min = h_min.replace('<br>','<br />')\n",
    "        x_min = x_min.replace('<hr>','<hr />')\n",
    "        return x_min\n",
    "\n",
    "    mini = x_minify(rendered)\n",
    "    #print(type(mini))\n",
    "    #display(HTML(rendered))\n",
    "    display(HTML(mini))\n",
    "\n",
    "    '''\n",
    "    #======== write to temp file to debug =======\n",
    "    path = Path.cwd() / 'debug' / 'narrative_pre.xhtml'\n",
    "    path.write_text(rendered, encoding=\"utf-8\")\n",
    "    path = Path.cwd() / 'debug' / 'narrative_mini_pre.xhtml'\n",
    "    path.write_text(mini, encoding=\"utf-8\")\n",
    "    #===================================================\n",
    "    '''\n",
    "    narr = construct_fhir_element('Narrative', dict(\n",
    "            status = 'additional', #'generated'\n",
    "            div = mini,\n",
    "            ))\n",
    "    cs.text = narr\n",
    "    #print(cs.json(indent=2))\n",
    "else:\n",
    "    print('=====================')\n",
    "    print('NO NARRATIVE ADDED')\n",
    "    print('=====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_me:\n",
    "    print('...validating')\n",
    "    r = validate(cs)\n",
    "    d = display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "            \n",
    "    #======== write to temp file to debug =======\n",
    "    from html.parser import HTMLParser\n",
    "\n",
    "    class HTMLFilter(HTMLParser):\n",
    "        text = \"\"\n",
    "        def handle_data(self, data):\n",
    "            self.text += data\n",
    "\n",
    "    f = HTMLFilter()\n",
    "    f.feed(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}')\n",
    "    path = Path.cwd() / 'debug' / 'validation.txt'\n",
    "    path.write_text(f.text, encoding=\"utf-8\")\n",
    "    #===================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "#save in ig_source folder\n",
    "#ig_source_path = ''\n",
    "\n",
    "path = Path.cwd()/ my_base / ig_source_path / 'resources' / f'capabilitystatement-{cs.id.lower()}.json'\n",
    "\n",
    "# path = Path.cwd() /  'resources' / f'capabilitystatement-{cs.id.lower()}.json' # write locally \n",
    "\n",
    "\n",
    "print(f'...........saving to file {path}............')\n",
    "path.write_text(cs.json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
