{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FHIR R4 CapStatement Resource\n",
    "\n",
    "\n",
    "### Outline:\n",
    "\n",
    "- Source excel with requirements\n",
    "- pandas to convert in python Ordered Dict\n",
    "- build json\n",
    "- generate narrative using Jinja2 templates\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- Python 3.6 or greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP1: Choose Source Spreadsheet to use\n",
    "\n",
    "*note:  Jupyteralab and widgets issues: see https://stackoverflow.com/questions/4\n",
    "9542417/how-to-get-ipywidgets-working-in-jupyter-lab for solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** NEED TO UPDATE WHEN Adding new IGS ************************************************\n",
    "\n",
    "in_path_list = [\n",
    "        \"---pick one below---\",\n",
    "        \"temp_source_spreadsheets/test-spreadsheet.xlsx\",\n",
    "        \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/source/source_spreadsheets/uscore-client.xlsx\",\n",
    "        \"//ERICS-AIR-2/ehaas/Documents/FHIR/US-Core-R4/source/source_spreadsheets/uscore-server.xlsx\",\n",
    "        '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Alerts/input/resources/source-data/capstatements-spreadsheets/alert-initiator.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Alerts/input/resources/source-data/capstatements-spreadsheets/notification-forwarder.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Alerts/input/resources/source-data/capstatements-spreadsheets/alert-receiver.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Alerts/input/resources/source-data/capstatements-spreadsheets/query-responder.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-Alerts/input/resources/source-data/capstatements-spreadsheets/query-requester.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_Consumer_Client.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_Reporter_Client.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_Consumer_Server.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_Producer_Client.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_Producer_Server.xlsx',\n",
    "         '//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_Receiver_Server.xlsx',\n",
    "         \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_GIC_Reporter_Client.xlsx\",\n",
    "          \"//ERICS-AIR-2/ehaas/Documents/FHIR/Davinci-DEQM/input/resources/source-data/DEQM_Capability_Statement_GIC_Receiver_Server.xlsx\",\n",
    "         'C:/Users/Administrator/Downloads/plan-net-server.xlsx'\n",
    "        ]\n",
    "\n",
    "#======================US Core ===================================\n",
    "# ----------spreadsheet source---------------\n",
    "from IPython.display import display as Display, HTML, Markdown, Javascript\n",
    "from ipywidgets import Dropdown\n",
    "menu = Dropdown(\n",
    "       options=in_path_list,\n",
    "       description='Choose Spreadsheet Source file',\n",
    "       style = {'description_width': 'initial',},\n",
    "       layout={'width': 'initial'},\n",
    "        )\n",
    "\n",
    "\n",
    "menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP2:  *CLICK HERE* and then 'Select Run Selected Cell and All Below'  from menu bar to continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = menu.value\n",
    "xls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FHIRClient and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhirclient.r4models.fhirabstractbase import FHIRValidationError\n",
    "from fhirclient.r4models import searchparameter as SP\n",
    "from fhirclient.r4models import capabilitystatement as CS\n",
    "from fhirclient.r4models import bundle as B\n",
    "from fhirclient.r4models import narrative as N\n",
    "import fhirclient.models.identifier as I\n",
    "import fhirclient.r4models.identifier as I\n",
    "import fhirclient.r4models.coding as C\n",
    "import fhirclient.r4models.codeableconcept as CC\n",
    "import fhirclient.r4models.fhirdate as D\n",
    "import fhirclient.r4models.extension as X\n",
    "import fhirclient.r4models.contactdetail as CD\n",
    "import fhirclient.r4models.fhirreference as FR\n",
    "from json import dumps, loads, load\n",
    "from requests import get, post, put\n",
    "import os\n",
    "from pathlib import Path\n",
    "from csv import reader as csvreader\n",
    "from IPython.display import display as Display, HTML, Markdown, Javascript\n",
    "import ipywidgets as widgets\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "from pandas import *\n",
    "from datetime import datetime, date\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "from stringcase import snakecase, titlecase\n",
    "#from itertools import zip_longest\n",
    "from openpyxl import load_workbook\n",
    "from commonmark import commonmark\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Assign Global Variables\n",
    "\n",
    "Here is where we assign all the global variables for this example such as the canonical base and project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhir_base_url = 'http://hl7.org/fhir/'\n",
    "f_jurisdiction =  CC.CodeableConcept({\n",
    "      \"coding\" : [\n",
    "        {\n",
    "          \"system\" : \"urn:iso:std:iso:3166\",\n",
    "          \"code\" : \"US\"\n",
    "        }\n",
    "      ]\n",
    "    })\n",
    "\n",
    "conf_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-expectation'\n",
    "combo_url = 'http://hl7.org/fhir/StructureDefinition/capabilitystatement-search-parameter-combination'\n",
    "\n",
    "sp_specials = {'us-core-includeprovenance':'http://hl7.org/fhir/us/core/SearchParameter/us-core-includeprovenance'}  # dict to for SP to get right canonicals, may use spreadsheet or package file in future.\n",
    "\n",
    "none_list = ['', ' ', 'none', 'n/a', 'N/A', 'N', 'False']\n",
    "\n",
    "sep_list = (',', ';', ' ', ', ', '; ')\n",
    "\n",
    "f_now = D.FHIRDate(str(date.today()))\n",
    "f_now.as_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conformance Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf(conf='MAY',as_dict=False):\n",
    "    if as_dict:\n",
    "        return [X.Extension(dict(\n",
    "            url = conf_url,\n",
    "            valueCode = conf\n",
    "            )).as_json()]\n",
    "    else:\n",
    "        return [X.Extension(dict(\n",
    "            url = conf_url,\n",
    "            valueCode = conf\n",
    "            ))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addin Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_addin_ext(py_ext, json_ext):            \n",
    "    print(py_ext)\n",
    "    if json_ext:   # ie not ''\n",
    "        addin_ext = X.Extension(loads(json_ext))            \n",
    "        # addin_ext.extension =  get_conf('SHALL') violates invariant   - DONT USE           \n",
    "        print(addin_ext)                 \n",
    "        py_ext.append(addin_ext) # add in other extensions\n",
    "    print(py_ext)\n",
    "    return py_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** validate Resource ********************************\n",
    "\n",
    "def validate(r):\n",
    "\n",
    "    #fhir_test_server = 'http://test.fhir.org/r4'\n",
    "    #fhir_test_server = 'http://hapi.fhir.org/baseR4'\n",
    "    fhir_test_server = 'http://wildfhir4.aegis.net/fhir4-0-1'\n",
    "    \n",
    "    headers = {\n",
    "    'Accept':'application/fhir+json',\n",
    "    'Content-Type':'application/fhir+json'\n",
    "    }\n",
    "\n",
    "    # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    " \n",
    "    params = dict(\n",
    "      # profile = 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient' # The official URL for this profile is: http://hl7.org/fhir/us/core/StructureDefinition/us-core-patient\n",
    "        )\n",
    "    \n",
    "    #   r = requests.post('https://httpbin.org/post', data = {'key':'value'})\n",
    "    r = post(f'{fhir_test_server}/Questionnaire/$validate', params = params, headers = headers, data = dumps(r.as_json()))\n",
    "    # return r.status_code\n",
    "    # view  output\n",
    "    # return (r.json()[\"text\"][\"div\"])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cap Statement input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to convert to dataframe series to namedtuple for easy peasy dot notation use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first the config data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_excel(xls,'config',na_filter = False,index_col=0)  # use the index_col = 0 for setting the first rwo as the index\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assign globals e.g. publisher parameter etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.[Column].[row] to get a value df.loc[[row],[Column]] or df.at[[column],[col]] works too\n",
    "df.Value.source #, df.loc['source','Value'], df.at['source' ,'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ig_source_path = df.Value.source\n",
    "ig_package_tar_path =  df.Value.packagepath\n",
    "# --------- ig specific variable -------------------\n",
    "pre = df.Value.pre  # for Titles - not sure this is actually used\n",
    "canon = df.Value.canon # don't forget the slash  - fix using os.join or path\n",
    "#\n",
    "publisher = df.Value.publisher\n",
    "#\n",
    "publisher_endpoint = dict(\n",
    "                    system = df.Value.publishersystem,\n",
    "                    value = df.Value.publishervalue,\n",
    "                  )\n",
    "\n",
    "pprint(publisher_endpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get IG Names\n",
    "\n",
    "until able to support primitive extensions in pyfhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_igs():\n",
    "    ig_dict = {}\n",
    "    df_igs = read_excel(xls,'igs',na_filter = False)\n",
    "    for ig in df_igs.itertuples(index=True):\n",
    "        ig_dict[ig.uri] = (ig.name, ig.url)\n",
    "        \n",
    "    return ig_dict # TODO add conformance to this and display extension\n",
    "\n",
    "ig_dict = get_igs()\n",
    "\n",
    "\n",
    "[*ig_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### then the meta sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_excel(xls,'meta',na_filter = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NamedTuple from df to use dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(df.Element, df.Value))\n",
    "meta = namedtuple(\"Meta\", d.keys())(*d.values())      \n",
    "         \n",
    "meta.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create CS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sys_op():\n",
    "    op_list = []\n",
    "    df_op = read_excel(xls,'ops',na_filter = False)\n",
    "    for i in df_op.itertuples(index=True):\n",
    "        if i.type == 'system':\n",
    "            op = CS.CapabilityStatementRestResourceOperation()\n",
    "            op.name = i.name \n",
    "            op.definition = i.definition\n",
    "            op.extension = get_conf(i.conf)           \n",
    "            op_list.append(op.as_json())\n",
    "    return op_list\n",
    "\n",
    "\n",
    "def get_rest_ints():\n",
    "    ri_list = []\n",
    "    df_ri = read_excel(xls,'rest_interactions',na_filter = False)\n",
    "    for i in df_ri.itertuples(index=True):\n",
    "        ri = CS.CapabilityStatementRestInteraction()\n",
    "        ri.code = i.code \n",
    "        ri.documentation = i.doc if i.doc not in none_list else None\n",
    "        ri.extension = get_conf(i.conf)\n",
    "        print(ri.as_json())\n",
    "        ri_list.append(ri.as_json())\n",
    "    return ri_list\n",
    "\n",
    "'''# TODO add conformance to this and display extension when support fhir primitives in pyfhir\n",
    "def get_igs():\n",
    "    ig_list = []\n",
    "    df_igs = read_excel(xls,'igs',na_filter = False)\n",
    "    for ig in df_igs.itertuples(index=True):\n",
    "        ig_list.append(ig.uri)\n",
    "    return ig_list \n",
    "'''\n",
    "def kebab_to_pascal(word):\n",
    "    return ''.join(x.capitalize() for x in word.split('-'))\n",
    "\n",
    "cs = CS.CapabilityStatement()\n",
    "cs.id = meta.id\n",
    "cs.url = f'{canon}CapabilityStatement/{meta.id}'\n",
    "cs.version = meta.version\n",
    "cs.name = f'{kebab_to_pascal(meta.id)}{cs.resource_type}'\n",
    "cs.title = f'{titlecase(meta.id).replace(\"Us \", \"US \")} {cs.resource_type}'\n",
    "cs.status = 'active'\n",
    "\n",
    "cs.experimental = False\n",
    "cs.date = f_now  # as FHIRDate\n",
    "cs.publisher = publisher\n",
    "cs.contact = [CD.ContactDetail( {\"telecom\" : [ publisher_endpoint ] })]\n",
    "cs.description = meta.description\n",
    "cs.jurisdiction = [f_jurisdiction]\n",
    "cs.kind = 'requirements'\n",
    "cs.fhirVersion = meta.fhirVersion\n",
    "cs.acceptUnknown = 'both'\n",
    "cs.format = [\n",
    "    \"xml\",\n",
    "    \"json\"\n",
    "  ]\n",
    "cs.patchFormat = [\n",
    "    \"application/json-patch+json\",\n",
    "  ]\n",
    "cs.implementationGuide = meta.ig.split(\",\") + [*ig_dict]\n",
    "rest = CS.CapabilityStatementRest(dict(\n",
    "    mode = meta.mode,\n",
    "    documentation = meta.documentation,\n",
    "    security = dict(\n",
    "        description = meta.security\n",
    "        ) if meta.security else None,\n",
    "    interaction = get_rest_ints(),\n",
    "    operation = get_sys_op()\n",
    "    ))\n",
    "cs.rest = [rest]\n",
    "\n",
    "\n",
    "cs.as_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then the list of IG profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_excel(xls,'profiles',na_filter = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add Resources\n",
    "\n",
    "- read sheets for resource attributes, interaction attributes,  search attributes, profiles, and combo search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resources = read_excel(xls,'resources',na_filter = False)\n",
    "df_resources = df_resources[df_resources.type.str[0] != '!']\n",
    "df_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profiles = read_excel(xls,'profiles',na_filter = False)  #df1 = df[df.Hostname.str[0] != \"abc\"]\n",
    "df_profiles = df_profiles[df_profiles.Profile.str[0] != '!']\n",
    "df_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = read_excel(xls,'interactions',na_filter = False)\n",
    "df_sp = read_excel(xls,'sps',na_filter = False)\n",
    "df_combos = read_excel(xls,'sp_combos',na_filter = False)\n",
    "df_op = read_excel(xls,'ops',na_filter = False)\n",
    "\n",
    "\n",
    "def get_i(type):\n",
    "    int_list = []\n",
    "    for i in df_i.itertuples(index=True):\n",
    "        #print(i.code, getattr(i,f'conf_{type}'))\n",
    "        if getattr(i,f'conf_{type}') not in none_list:\n",
    "            int  = CS.CapabilityStatementRestResourceInteraction()\n",
    "            int.code = i.code\n",
    "            try:\n",
    "                int.documentation = getattr(i,f'doc_{type}') if getattr(i,f'doc_{type}') not in none_list else None\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            int.extension = get_conf(getattr(i,f'conf_{type}'))    \n",
    "            int_list.append(int.as_json())\n",
    "        \n",
    "    return int_list\n",
    "\n",
    "\n",
    "def get_sp(r_type):\n",
    "    sp_list = []\n",
    "    for i in df_sp.itertuples(index=True):\n",
    "        if i.base == r_type:\n",
    "            sp  = CS.CapabilityStatementRestResourceSearchParam()\n",
    "            sp.name = i.code\n",
    "            \n",
    "            # TODO need to fix this to reference the package file to reconcile definition to names\n",
    "            if i.code in sp_specials: #special case temp fix for us-core\n",
    "                sp.definition = sp_specials[i.code]\n",
    "            elif i.update == 'Y' or i.exists =='N':\n",
    "                sp.definition = (f'{canon}SearchParameter/{pre.lower()}-{i.base.lower()}-{i.code.split(\"_\")[-1]}')                  \n",
    "            else:  # use base definition\n",
    "                sp.definition = f'{fhir_base_url}SearchParameter/{i.base}-{i.code.split(\"_\")[-1]}'  # removes the '_' for things like _id\n",
    "                                 \n",
    "            # print(sp.definition)\n",
    "                                 \n",
    "            sp.type = i.type\n",
    "            sp.extension = get_conf(i.base_conf)\n",
    "            #print(sp.as_json())                \n",
    "            sp_list.append(sp.as_json())\n",
    "                             \n",
    "    return sp_list\n",
    "\n",
    "\n",
    "def get_combo_ext(r_type,combos):\n",
    "    x_list = []\n",
    "    for combo in combos:\n",
    "        # convert to extension\n",
    "        combo_ext = X.Extension()\n",
    "        combo_ext.url = combo_url\n",
    "        combo_conf_ext = get_conf(combo[1])\n",
    "        combo_ext.extension=combo_conf_ext\n",
    "        for param in combo[0].split(','):\n",
    "            req_combo = X.Extension(\n",
    "                dict (\n",
    "                    url = 'required',\n",
    "                    valueString = param   #http://hl7.org/fhir/us/core/SearchParameter/us-core-patient-family\n",
    "                    )\n",
    "                )\n",
    "            combo_ext.extension.append(req_combo)\n",
    "        x_list.append(combo_ext)\n",
    "        # print(x_list)\n",
    "    return x_list\n",
    "                             \n",
    "def get_op(r_type):\n",
    "    op_list = []\n",
    "    for i in df_op.itertuples(index=True):\n",
    "         if i.type == r_type:\n",
    "            op = CS.CapabilityStatementRestResourceOperation()\n",
    "            op.name = i.name \n",
    "            op.definition = i.definition\n",
    "            op.documentation = i.documentation if i.documentation not in none_list else None\n",
    "            op.extension = get_conf(i.conf)\n",
    "            try:                     \n",
    "                op.extension =  get_addin_ext(op.extension, i.ext)\n",
    "            except AttributeError:\n",
    "                print(\"---- no addin extensions found-----\")\n",
    "            op_list.append(op.as_json())\n",
    "                           \n",
    "    return op_list \n",
    "\n",
    "rest.resource =  []\n",
    "for r in df_resources.itertuples(index=True):\n",
    "    # print(r.type, r.conformance, r.readHistory)\n",
    "    supported_profile = [p.Profile for p in df_profiles.itertuples(index=True) if p.Type == r.type]\n",
    "    #pprint(supported_profile)                         \n",
    "    res = CS.CapabilityStatementRestResource(\n",
    "    dict(\n",
    "        type = r.type,\n",
    "        documentation = r.documentation if r.documentation not in none_list else None,\n",
    "        versioning = r.versioning if r.versioning not in none_list else None,\n",
    "        readHistory = r.readHistory if r.readHistory not in none_list else None,\n",
    "        updateCreate = r.updateCreate if r.updateCreate not in none_list else None,\n",
    "        conditionalCreate = r.conditionalCreate if r.conditionalCreate not in none_list else None,\n",
    "        conditionalRead = r.conditionalRead if r.conditionalRead not in none_list else None,\n",
    "        conditionalUpdate = r.conditionalUpdate if r.conditionalUpdate not in none_list else None,\n",
    "        conditionalDelete = r.conditionalDelete if r.conditionalDelete not in none_list else None,\n",
    "        referencePolicy = [x for x in r.referencePolicy.split(\",\") if x],\n",
    "        searchInclude =  [x for x in r.shall_include.split(\",\") + r.should_include.split(\",\") if x],\n",
    "        searchRevInclude =  [x for x in r.shall_revinclude.split(\",\") + r.should_revinclude.split(\",\") if x],\n",
    "        interaction = get_i(r.type),\n",
    "        searchParam = get_sp(r.type),\n",
    "        operation = get_op(r.type),\n",
    "        profile = r.profile if r.profile not in none_list else None,\n",
    "        supportedProfile = supported_profile,\n",
    "        )\n",
    "    )\n",
    "    res.extension = get_conf(r.conformance)\n",
    "    combos = {(i.combo,i.combo_conf) for i in df_combos.itertuples(index=True) if i.base == r.type}\n",
    "    res.extension = res.extension + get_combo_ext(r.type,combos) # convert list to  lst of combo extension\n",
    "\n",
    "\n",
    "    '''\n",
    "    #TODO add in conformance expectations for primitives \n",
    "    #need to convert to dict since model can't handle primitive extensions\n",
    "\n",
    "    resttype_dict = res.as_json()\n",
    "\n",
    "    for i in ['Include','RevInclude']:\n",
    "        element = f'_search{i}'\n",
    "\n",
    "        resttype_dict[element] = []\n",
    "        print(element)\n",
    "        for expectation in ['should', 'shall']: # list all should includes first\n",
    "            sp_attr = f'{expectation}_{i.lower()}'\n",
    "            print(sp_attr) \n",
    "            includes = getattr(r,sp_attr).split(',')\n",
    "            print(includes)\n",
    "\n",
    "            for include in includes:\n",
    "                if include not in none_list:             \n",
    "                    print(include)\n",
    "                    conf = get_conf(expectation.upper(),as_dict=True)\n",
    "                    print(conf)\n",
    "                    conf = conf\n",
    "                    print(conf)        \n",
    "                    resttype_dict[element].append(conf)\n",
    "\n",
    "        if not resttype_dict[element]:\n",
    "                del(resttype_dict[element])\n",
    "\n",
    "    print(dumps(resttype_dict, indent = 4))\n",
    "    res = CS.CapabilityStatementRestResource(resttype_dict, strict = False)\n",
    "    print('++++++++++++++++RES.__dict__+++++++++++++++++++')\n",
    "    print(dumps(res._searchRevInclude, indent = 4))\n",
    "    '''                               \n",
    "\n",
    "    rest.resource.append(res)\n",
    "\n",
    "rest.resource =  sorted(rest.resource,key = lambda x: x.type)  # sort resources                         \n",
    "cs.rest = [rest]\n",
    "    \n",
    "print(dumps(cs.as_json(),indent=3))    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model to dict and add extensions to primitives **Deactivated ( marked a raw block ) since will need to use dict in subsuquent steps."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "#add in conformance expectations for primitives \n",
    "#convert to dict since model can't handle primitive extensions\n",
    "\n",
    "resttype_dict = res.as_json()\n",
    "\n",
    "for i in ['Include','RevInclude']:\n",
    "    element = f'_search{i}'\n",
    "\n",
    "    resttype_dict[element] = []\n",
    "    print(element)\n",
    "    for expectation in ['should', 'shall']: # list all should includes first\n",
    "        sp_attr = f'{expectation}_{i.lower()}'\n",
    "        print(sp_attr) \n",
    "        includes = getattr(r,sp_attr).split(',')\n",
    "        print(includes)\n",
    "\n",
    "        for include in includes:\n",
    "            if include not in none_list:             \n",
    "                print(include)\n",
    "                conf = get_conf(expectation.upper(),as_dict=True)\n",
    "                print(conf)\n",
    "                conf = conf\n",
    "                print(conf)        \n",
    "                resttype_dict[element].append(conf)\n",
    "\n",
    "    if not resttype_dict[element]:\n",
    "            del(resttype_dict[element])\n",
    "\n",
    "print(resttype_dict)\n",
    "\n",
    "print(dumps(cs.as_json(),indent=3))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #validate and write to file\n",
    "\n",
    "print('...validating')\n",
    "r = validate(cs)\n",
    "display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Narrative\n",
    "\n",
    "- Using Jinja2 Template create xhtml for narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First: Get spec_internal from package.tgz a json file which includes canonical to local relative page links\n",
    "\n",
    "Note for this to work you have to have a working build that already contains all the needed artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "package_path = Path.cwd() / 'tarfiles'/'package.tgz'  #get_si(path)\n",
    "\n",
    "def get_si(package_path):\n",
    "    with tarfile.open(package_path, mode='r') as tf:\n",
    "        #pprint(tf.getnames())\n",
    "        f = tf.extractfile('package/other/spec.internals')\n",
    "        r = f.read()\n",
    "        si = loads(r)\n",
    "        return si\n",
    "\n",
    "    \n",
    "def get_si3(path):\n",
    "    tf = get(f'{path}/package.tgz')\n",
    "    return tf\n",
    "\n",
    "\"e.g. https://build.fhir.org/ig/HL7/davinci-deqm/package.tgz\" \n",
    "try:   \n",
    "    tf= get_si3(ig_package_tar_path) # get from remote server\n",
    "except:\n",
    "   in_path = Path() / ig_package_tar_path /'package.tgz'\n",
    "   tf = in_path.read_bytes()\n",
    "   package_path.write_bytes(tf)  # get from package (json) file in local .fhir directory\n",
    "else:\n",
    "    package_path.write_bytes(tf.content)    #save in temp file\n",
    "    \n",
    "si = get_si(package_path) #unpack from file\n",
    "\n",
    "path_map = si['paths']\n",
    "path_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then Use Jinja2 template to create narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = ''\n",
    "in_file = 'R4capabilitystatement-server.j2'\n",
    "\n",
    "def markdown(text, *args, **kwargs):\n",
    "    return commonmark(text, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "env = Environment(\n",
    "    loader=FileSystemLoader(searchpath = in_path),\n",
    "    autoescape=select_autoescape(['html','xml','xhtml','j2','md'])\n",
    "    )\n",
    "\n",
    "env.filters['markdown'] = markdown\n",
    "\n",
    "\n",
    "template = env.get_template(in_file)\n",
    "\n",
    "sp_map = {sp.code:sp.type for sp in df_sp.itertuples(index=True)}\n",
    "pname_map = {p.Profile:p.Name for p in df_profiles.itertuples(index=True)}\n",
    "pprint(pname_map)\n",
    "rendered = template.render(cs=cs, path_map=path_map, pname_map=pname_map, sp_map=sp_map, ig_dict=ig_dict )\n",
    "print(type(rendered))\n",
    "display(HTML(rendered))\n",
    "\n",
    "\n",
    "#======== write to temp file to debug =======\n",
    "path = Path.cwd() / 'debug' / 'narrative.xhtml'\n",
    "path.write_text(rendered, encoding=\"utf-8\")\n",
    "#===================================================\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "root = etree.fromstring(rendered, parser=parser)\n",
    "\n",
    "div = (etree.tostring(root[1][0], encoding='unicode', method='html'))\n",
    "narr = N.Narrative()\n",
    "narr.status = 'generated'\n",
    "narr.div = div\n",
    "cs.text = narr\n",
    "\n",
    "\n",
    "#print(dumps(cs.as_json(),indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...validating')\n",
    "r = validate(cs)\n",
    "d = display(HTML(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}'))\n",
    "           \n",
    "#======== write to temp file to debug =======\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class HTMLFilter(HTMLParser):\n",
    "    text = \"\"\n",
    "    def handle_data(self, data):\n",
    "        self.text += data\n",
    "\n",
    "f = HTMLFilter()\n",
    "f.feed(f'<h1>Validation output</h1><h3>Status Code = {r.status_code}</h3> {r.json()[\"text\"][\"div\"]}')\n",
    "path = Path.cwd() / 'debug' / 'validation.txt'\n",
    "path.write_text(f.text)\n",
    "#===================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........saving to file /Users/ehaas/Documents/Python/MyNotebooks/CapStatement/resources/capabilitystatement-test.json............\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "276611"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save to file\n",
    "#save in ig_source folder\n",
    "path = Path.cwd() / ig_source_path / 'resources' / f'capabilitystatement-{cs.id.lower()}.json'\n",
    "\n",
    "#path = Path.cwd() /  'resources' / f'capabilitystatement-{cs.id.lower()}.json' # write locally \n",
    "\n",
    "\n",
    "print(f'...........saving to file {path}............')\n",
    "path.write_text(dumps(cs.as_json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
